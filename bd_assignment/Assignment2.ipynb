{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "# CSIT 5800 Introduction to Big Data\n",
    "### Assignment 2 - Data Prediction using Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "In this assignment, you will have an opportunity to apply machine learning techniques that you learned in the class to a problem. \n",
    "\n",
    "To get started on this assignment, you need to download the given dataset and read the description carefully written on this page. Please note that all implementation of your program should be done with Python.\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intended Learning Outcomes\n",
    "\n",
    "- Upon completion of this assignment, you should be able to:\n",
    "<ol>\n",
    "    <li>Demonstrate your understanding on how to do prediction using the machine learning algorithms / techniques as described in the class.</li>\n",
    "    <li>Construct Python program to learn from the training data and do data prediction for the testing set.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries\n",
    "The following libraries are required for this assignment:\n",
    "<ol>\n",
    "    <li>numpy - Numerical python</li>\n",
    "    <li>Scipy - Scientific python</li>\n",
    "    <li>Matplotlib - Python 2D plotting library</li>\n",
    "    <li>Seaborn - Visualization library based on matplotlib</li>\n",
    "    <li>Pandas - Python data analysis library</li>\n",
    "    <li>Scikit-learn - Python Machine learning library </li>\n",
    "    <li>Keras - Deep learning library</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset ~ House Prices (house-train.csv and house-test.csv)\n",
    "\n",
    "This dataset consists of sales prices of houses in Ames, Iowa.\n",
    "\n",
    "The training dataset has 1460 instances with unique Ids, sales prices, and 79 more features.\n",
    "\n",
    "<ul>\n",
    "<li>Pricing — Monetary values, one of which is the sales price we are trying to determine<br />\n",
    "Examples: SalePrice, MiscVal    \n",
    "   <ul>\n",
    "   <li>SalePrice — the property's sale price in dollars. This is the target variable that you're trying to predict.</li>\n",
    "   </ul>\n",
    "</li> \n",
    "<li>Dates — Time based data about when it was built, remodeled or sold.<br />\n",
    "Example: YearBuilt, YearRemodAdd, GarageYrBlt, YrSold\n",
    "</li>\n",
    "<li>Quality/Condition — There are categorical assessment of the various features of the houses, most likely from the property assessor.<br />\n",
    "Example: PoolQC, SaleCondition, GarageQual, HeatingQC\n",
    "</li>\n",
    "<li>Property Features — Categorical collection of additional features and attributes of the building<br />\n",
    "Example: Foundation, Exterior1st, BsmtFinType1, Utilities\n",
    "</li>\n",
    "<li>Square Footage — Area measurement of section of the building and features like porches and lot area(which is in acres)<br />\n",
    "Example: TotalBsmtSF, GrLivArea, GarageArea, PoolArea, LotArea\n",
    "</li>\n",
    "<li>Room/Feature Count — Quantitative counts of features (versus categorical) like rooms, prime candidate for feature engineering<br />\n",
    "Example: FullBath, BedroomAbvGr, Fireplaces,GarageCars\n",
    "</li>\n",
    "<li>Neighborhood — Information about the neighborhood, zoning and lot.<br />\n",
    "Examples: MSSubClass, LandContour, Neighborhood, BldgType\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "The testing dataset has 1459 instances. It does not have the feature SalePrice, but with unique Ids and the other 79 features.\n",
    "\n",
    "You may refer to the data description for more details (data_description.txt). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Installation and Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.1 \n",
    "We are going to use Keras package which will be using Tensorflow as backend.\n",
    "Therefore, you will need to install Tensorflow and Keras first.\n",
    "<br/>\n",
    "<ol>\n",
    "   <li>To install Tesnsorflow:\n",
    "      <ul>\n",
    "         <li>Start the \"Anaconda Prompt\" and enter the following command:<br />\n",
    "         pip install --ignore-installed --upgrade tensorflow \n",
    "         </li>         \n",
    "         <li>For more information on installing Tensorflow: <url>https://www.tensorflow.org/install/</url></li>\n",
    "      </ul>\n",
    "   </li>\n",
    "   <li>To install Keras:\n",
    "      <ul>\n",
    "         <li>In the \"Anaconda Prompt\", enter the following command:<br />\n",
    "         pip install keras \n",
    "         </li>\n",
    "         <li>For more information on installing Keras: <url>https://keras.io/#installation</url>.</li>\n",
    "      </ul>\n",
    "   </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.2\n",
    "To start working, you will need to import the required libraries\n",
    "- Import the following libraries using import statements.\n",
    "<ul>\n",
    "<li>pandas (for data manipulation)</li>\n",
    "<li>numpy (for multidimensional array computation)</li>\n",
    "<li>seaborn and matplotlib.pyplot (both for data visualization)</li>\n",
    "</ul>\n",
    "​\n",
    "Note: Run a code cell by clicking on the cell and using the keyboard shortcut &lt;Shift&gt; + &lt;Enter&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------- From Assignment 1 -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing\n",
    "\n",
    "### Steps for preprocessing the training data:\n",
    "<ol>\n",
    "<li>Importing data and exploring the features.</li>\n",
    "<li>Cleaning data: Handling missing values</li>\n",
    "<li><del>Creating new features and</del> dropping redundant features.</li>\n",
    "<li>Transforming data.</li>\n",
    "</ol>\n",
    "\n",
    "<strong>Note 1:</strong> In this assignment, since we are focusing on learning different models, we are not considering new features yet.   \n",
    "<strong>Note 2:</strong> The following code is given to you, run the code cell by clicking on the cell and using the keyboard shortcut &lt;Shift&gt; + &lt;Enter&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.283204</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.860786</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.931826</td>\n",
       "      <td>4.454347</td>\n",
       "      <td>9.555064</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.597146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.330733</td>\n",
       "      <td>9.218804</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>5.231109</td>\n",
       "      <td>7.222566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.263383</td>\n",
       "      <td>9.247925</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1973</td>\n",
       "      <td>1973</td>\n",
       "      <td>5.484797</td>\n",
       "      <td>6.756932</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>8.719481</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1931</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.252273</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>8.912069</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    4.110874     4.189655  9.042040            7            5       2003   \n",
       "1    3.044522     4.394449  9.169623            6            8       1976   \n",
       "2    4.110874     4.234107  9.328212            7            5       2001   \n",
       "3    4.262680     4.110874  9.164401            7            5       1915   \n",
       "4    4.110874     4.442651  9.565284            8            5       2000   \n",
       "5    3.931826     4.454347  9.555064            5            5       1993   \n",
       "6    3.044522     4.330733  9.218804            8            5       2004   \n",
       "7    4.110874     4.263383  9.247925            7            6       1973   \n",
       "8    3.931826     3.951244  8.719481            7            5       1931   \n",
       "9    5.252273     3.931826  8.912069            5            6       1939   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2          ...            \\\n",
       "0          2003    5.283204    6.561031    0.000000          ...             \n",
       "1          1976    0.000000    6.886532    0.000000          ...             \n",
       "2          2002    5.093750    6.188264    0.000000          ...             \n",
       "3          1970    0.000000    5.379897    0.000000          ...             \n",
       "4          2000    5.860786    6.486161    0.000000          ...             \n",
       "5          1995    0.000000    6.597146    0.000000          ...             \n",
       "6          2005    5.231109    7.222566    0.000000          ...             \n",
       "7          1973    5.484797    6.756932    3.496508          ...             \n",
       "8          1950    0.000000    0.000000    0.000000          ...             \n",
       "9          1950    0.000000    6.747587    0.000000          ...             \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "5               0             0             0            1   \n",
       "6               0             0             0            1   \n",
       "7               0             0             0            1   \n",
       "8               0             0             0            1   \n",
       "9               0             0             0            1   \n",
       "\n",
       "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      1                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "5                      0                      0                     0   \n",
       "6                      0                      0                     0   \n",
       "7                      0                      0                     0   \n",
       "8                      1                      0                     0   \n",
       "9                      0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     0                      0  \n",
       "4                     0                     1                      0  \n",
       "5                     0                     1                      0  \n",
       "6                     0                     1                      0  \n",
       "7                     0                     1                      0  \n",
       "8                     0                     0                      0  \n",
       "9                     0                     1                      0  \n",
       "\n",
       "[10 rows x 301 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# Step 1.1 Load the training data\n",
    "trainData = pd.read_csv('house-train.csv')\n",
    "\n",
    "# Step 1.2 Handling not Really NA values\n",
    "# NA means \"no alley access\". Use fillna function to replace those NA values with \"None\".\n",
    "trainData[\"Alley\"].fillna(\"None\", inplace=True)\n",
    "trainData[\"BsmtQual\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"BsmtCond\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"BsmtExposure\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"BsmtFinType1\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"BsmtFinType2\"].fillna(\"No\", inplace=True)\n",
    "# Fence : data description says NA means \"no fence\"\n",
    "trainData[\"Fence\"].fillna(\"No\", inplace=True)\n",
    "# FireplaceQu : data description says NA means \"no fireplace\"\n",
    "trainData[\"FireplaceQu\"].fillna(\"No\", inplace=True)\n",
    "# Functional : data description says NA means typical\n",
    "trainData[\"Functional\"].fillna(\"Typ\", inplace=True)\n",
    "# GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "trainData[\"GarageType\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"GarageFinish\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"GarageQual\"].fillna(\"No\", inplace=True)\n",
    "trainData[\"GarageCond\"].fillna(\"No\", inplace=True)\n",
    "# PoolQC : data description says NA for pool quality is \"no pool\"\n",
    "trainData[\"PoolQC\"].fillna(\"No\", inplace=True)\n",
    "# MiscFeature: Miscellaneous feature not covered in other categories, NA means no miscellaneous features\n",
    "trainData[\"MiscFeature\"].fillna(\"No\", inplace=True)\n",
    "\n",
    "# Step 1.3 Use mean / median to impute the missing values of the feature.\n",
    "ltf_mean = trainData[\"LotFrontage\"].mean(skipna=True)\n",
    "trainData[\"LotFrontage\"].fillna(ltf_mean, inplace=True)\n",
    "pa_mean = trainData[\"PoolArea\"].mean(skipna=True)\n",
    "trainData[\"PoolArea\"].fillna(pa_mean, inplace=True)\n",
    "\n",
    "# Step 1.4\n",
    "# Use the most common value of the feature to impute the missing values. \n",
    "trainData[\"MasVnrType\"].fillna(\"None\", inplace=True)\n",
    "trainData[\"MasVnrArea\"].fillna(\"0\", inplace=True)\n",
    "\n",
    "# Step 1.5 Remove the instance with missing value on the feature 'Electical\"\n",
    "# Drop the instance\n",
    "trainData = trainData.drop(trainData.loc[trainData['Electrical'].isnull()].index)\n",
    "\n",
    "# Step 1.6 Remove certain features if necessary\n",
    "# Drop the feature 'GarageYrBlt'\n",
    "trainData = trainData.drop(['GarageYrBlt'], axis=1)\n",
    "\n",
    "# Drop the feature 'id'\n",
    "trainData = trainData.drop(['Id'], axis=1)\n",
    "\n",
    "# Step 1.7 Change the type of MasVnrArea to float\n",
    "trainData['MasVnrArea'] = trainData['MasVnrArea'].astype(float)\n",
    "\n",
    "# Step 1.8 Normalize the numerical features\n",
    "numeric_feats = trainData.dtypes[trainData.dtypes != \"object\"].index\n",
    "skewed_feats = trainData[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "for feat in skewed_feats.index:\n",
    "   trainData[feat] = np.log1p(trainData[feat])\n",
    "\n",
    "# Step 1.9 convert categorical features into dummy/indicator features\n",
    "trainData = pd.get_dummies(trainData)\n",
    "\n",
    "# Review the first 10 rows\n",
    "trainData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------- Complete the following -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing Training and Validation Datasets  (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1  Prepare training data - feature set and target set\n",
    "- Build target set Y by extracting 'SalePrice' from trainData.\n",
    "- Build feature set X by excluding/dropping the 'SalePrice' from trainData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "train_Y = trainData['SalePrice']\n",
    "train_X = trainData.drop(columns = 'SalePrice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 300) (1459,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2 Split the data into training and validation datasets\n",
    "\n",
    "Using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">sklearn.model_selection.train_test_split()</a> function to split the training data, feature set and target set (i.e. X and Y), into two subsets for training and validation, i.e. X_train, X_valid, Y_train, Y_valid.\n",
    "\n",
    "<ul>\n",
    "<li>Set test_size to 0.3. test_size is the proportion of the dataset to include in the test split. <li>Set random_state to 0. An integer value is the seed used by the random number generator.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_X, train_Y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3\n",
    "Using <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html\">pandas.DataFrame.shape</a> function to view the dimensionality of the training and validation datasets of features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1021, 300) (438, 300) (1021,) (438,)\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "print(X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training the Regression model using Sklearn  (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">sklearn.linear_model.LinearRegression</a> to build a linear gression model.\n",
    "\n",
    "### Step 3.1 \n",
    "Import the LinearRegression from sklearn.linear_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 \n",
    "Build the linear regression model by:\n",
    "<ol>\n",
    "<li>Initialize a Linear Regression model by LinearRegression() function.</li>\n",
    "<li>Call fit() function to train the linear regression model using the training feature data (i.e. X_train).</li>\n",
    "<li>Predict the target values for the validation feature data (i.e. X_valid) using the predict() function.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, Y_train)\n",
    "valid_predict = linear_model.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3\n",
    "Using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\">sklearn.metrics.mean_squared_error</a> to\n",
    "evaluate the predicted target values by computing \"Root Mean Squred Error (RMSE)\":\n",
    "<ol>\n",
    "   <li>Import mean_squared_error from sklearn.metrics module.</li>\n",
    "   <li>Compute the mean squared error (MSE) by using mean_squared_error() function on the validation target data (i.e. Y_valid) and the predicted target values.</li>\n",
    "   <li>Compute the RMSE by otaining the square-root of the MSE using <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.sqrt.html\">numpy.sqrt()</a> function.</li>\n",
    "   <li>Print the RMSE</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6047737280536616\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(valid_predict, Y_valid)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4\n",
    "Explore the validation target values vs the predicted target values using scatter function \n",
    "(<a href=\"https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html\">matplotlib.pyplot.scatter</a>) of matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f18a448160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put your statements here\n",
    "plt.scatter(x=Y_valid, y=valid_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">What is your observation?</span> (Write your observation here.)\n",
    "\n",
    "Except some of the possible outliers are not match, most of the point in the validation sets can be predicted properly by regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training the Decision Tree model using  Sklearn (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">sklearn.tree.DecisionTreeRegressor</a> to build a Decision Tree model for Regression Problem.\n",
    "\n",
    "(Reference:<a href=\"https://scikit-learn.org/stable/modules/tree.html#tree\">Decision Tree User Guide from Scikit-learn</a>)\n",
    "\n",
    "### Step 4.1 \n",
    "Import the DecisionTreeRegressor from sklearn.tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 \n",
    "Build the Decision Tree model by:\n",
    "<ol>\n",
    "<li>Initialize a Decision Tree model by DecisionTreeRegressor() function.</li>\n",
    "<li>Call fit() function to train the model using the training feature data (i.e. X_train).</li>\n",
    "<li>Predict the target values for the validation feature data (i.e. X_valid) using the predict() function.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "tree_model = DecisionTreeRegressor()\n",
    "tree_model.fit(X_train, Y_train)\n",
    "tree_valid_predict = tree_model.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3\n",
    "Using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\">sklearn.metrics.mean_squared_error</a> to\n",
    "evaluate the predicted target values by computing \"Root Mean Squred Error (RMSE)\":\n",
    "<ol>\n",
    "   <li>Import mean_squared_error from sklearn.metrics module,</li>\n",
    "   <li>Compute the mean squared error (MSE) by using mean_squared_error() function on the validation target data (i.e. Y_valid) and the predicted target values.</li>\n",
    "   <li>Compute the RMSE by otaining the square-root of the MSE using <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.sqrt.html\">numpy.sqrt()</a> function.</li>\n",
    "   <li>Print the RMSE.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20721271575635983\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(tree_valid_predict, Y_valid)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f194366a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=Y_valid, y=tree_valid_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 -- Standardization and Rescaling (10 points)\n",
    "\n",
    "Rescaling and Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn.\n",
    "They might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "(Reference: <a href=\"https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\">here</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs the rescaling by:\n",
    "<ol>\n",
    "<li>Import the MinMaxScaler from sklearn.preprocessing module.</li>\n",
    "<li>Initializing a MinMaxScaler by using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">sklearn.preprocessing.MinMaxScaler</a> function, which transforms the numerical features by scaling each feature to a given range of [0, 1], i.e. between zero to one.</li>\n",
    "<li>Compute the minimum and maximum to be used for later scalingby using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.fit\">sklearn.preprocessing.MinMaxScaler.fit()</a> function.</li>\n",
    "<li>Transform the data using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.transform\">sklearn.preprocessing.MinMaxScaler.transform()</a> function.</li>\n",
    "<li>The tranformed data is an numpy array. Convert it into a pandas.DataFrame using\n",
    "pandas.DataFrame() function with pandas.DataFrame.columns.</li>\n",
    "<li>Using the pandas.DataFrame.head() function to preview the data.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "all_feature_scaler = MinMaxScaler()\n",
    "all_feature_scaler.fit(train_X)\n",
    "sca_all_feature = all_feature_scaler.transform(train_X)\n",
    "sca_all_feature = pd.DataFrame(sca_all_feature)\n",
    "\n",
    "train_scaler = MinMaxScaler()\n",
    "train_scaler.fit(X_train)\n",
    "sca_train_X = train_scaler.transform(X_train)\n",
    "sca_train_X = pd.DataFrame(sca_train_X)\n",
    "\n",
    "valid_scaler = MinMaxScaler()\n",
    "valid_scaler.fit(X_valid)\n",
    "sca_valid_X = valid_scaler.transform(X_valid)\n",
    "sca_valid_X = pd.DataFrame(sca_valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the first 10 rows of the training feature set using pandas.DataFrame.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395769</td>\n",
       "      <td>0.342929</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499482</td>\n",
       "      <td>0.432954</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.722749</td>\n",
       "      <td>0.759180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483003</td>\n",
       "      <td>0.461356</td>\n",
       "      <td>0.351706</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.720770</td>\n",
       "      <td>0.618984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551764</td>\n",
       "      <td>0.641280</td>\n",
       "      <td>0.461253</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.483003</td>\n",
       "      <td>0.407525</td>\n",
       "      <td>0.370465</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.609810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.401904</td>\n",
       "      <td>0.316280</td>\n",
       "      <td>0.378613</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.664177</td>\n",
       "      <td>0.440738</td>\n",
       "      <td>0.396118</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.582589</td>\n",
       "      <td>0.441003</td>\n",
       "      <td>0.433085</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389750</td>\n",
       "      <td>0.354161</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.713258</td>\n",
       "      <td>0.787962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440738</td>\n",
       "      <td>0.380776</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3      4         5         6    \\\n",
       "0  0.000000  0.395769  0.342929  0.666667  0.500  0.953846  0.916667   \n",
       "1  0.000000  0.499482  0.432954  0.666667  0.500  0.753846  0.466667   \n",
       "2  0.483003  0.461356  0.351706  0.555556  0.750  0.753846  0.466667   \n",
       "3  0.551764  0.641280  0.461253  0.555556  0.750  0.423077  0.600000   \n",
       "4  0.483003  0.407525  0.370465  0.555556  0.500  0.961538  0.916667   \n",
       "5  0.401904  0.316280  0.378613  0.555556  0.625  0.438462  0.000000   \n",
       "6  0.664177  0.440738  0.396118  0.333333  0.500  0.630769  0.200000   \n",
       "7  0.582589  0.441003  0.433085  0.555556  0.625  0.276923  0.733333   \n",
       "8  0.000000  0.389750  0.354161  0.333333  0.500  0.623077  0.183333   \n",
       "9  0.000000  0.440738  0.380776  0.555556  0.625  0.607692  0.150000   \n",
       "\n",
       "        7         8    9   ...   290  291  292  293  294  295  296  297  298  \\\n",
       "0  0.000000  0.696715  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1  0.722749  0.759180  0.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2  0.720770  0.618984  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3  0.000000  0.745607  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4  0.000000  0.609810  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "5  0.000000  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6  0.000000  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "7  0.000000  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "8  0.713258  0.787962  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "9  0.000000  0.742993  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "   299  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "5  0.0  \n",
       "6  0.0  \n",
       "7  0.0  \n",
       "8  0.0  \n",
       "9  0.0  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your statement here\n",
    "sca_train_X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the first 10 rows of the standardized validation feature set using pandas.DataFrame.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483003</td>\n",
       "      <td>0.684664</td>\n",
       "      <td>0.438343</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.861080</td>\n",
       "      <td>0.796318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.176408</td>\n",
       "      <td>0.405442</td>\n",
       "      <td>0.286715</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.664177</td>\n",
       "      <td>0.491783</td>\n",
       "      <td>0.333846</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.664177</td>\n",
       "      <td>0.565326</td>\n",
       "      <td>0.328764</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622538</td>\n",
       "      <td>0.410682</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.892602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.611449</td>\n",
       "      <td>0.491783</td>\n",
       "      <td>0.331864</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.605839</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514934</td>\n",
       "      <td>0.342632</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.683404</td>\n",
       "      <td>0.865245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.922605</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.118336</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.872772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.922605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058301</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.626212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610329</td>\n",
       "      <td>0.371913</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.483003  0.684664  0.438343  0.428571  0.500000  0.700730  0.305085   \n",
       "1  0.176408  0.405442  0.286715  0.285714  0.833333  0.481752  0.779661   \n",
       "2  0.664177  0.491783  0.333846  0.142857  0.333333  0.562044  0.000000   \n",
       "3  0.664177  0.565326  0.328764  0.285714  0.333333  0.781022  0.491525   \n",
       "4  0.000000  0.622538  0.410682  0.285714  0.666667  0.678832  0.254237   \n",
       "5  0.611449  0.491783  0.331864  0.285714  0.333333  0.605839  0.084746   \n",
       "6  0.000000  0.514934  0.342632  0.571429  0.333333  0.963504  0.932203   \n",
       "7  0.922605  0.061644  0.118336  0.714286  0.333333  0.927007  0.847458   \n",
       "8  0.922605  0.000000  0.058301  0.142857  0.333333  0.715328  0.338983   \n",
       "9  0.000000  0.610329  0.371913  0.142857  0.500000  0.620438  0.118644   \n",
       "\n",
       "        7         8    9   ...   290  291  292  293  294  295  296  297  298  \\\n",
       "0  0.861080  0.796318  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1  0.000000  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2  0.000000  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3  0.000000  0.908558  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4  0.731014  0.892602  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "5  0.000000  0.789601  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6  0.683404  0.865245  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "7  0.872772  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "8  0.626212  0.000000  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "9  0.000000  0.751559  0.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "   299  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "5  0.0  \n",
       "6  0.0  \n",
       "7  0.0  \n",
       "8  0.0  \n",
       "9  0.0  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your statement here\n",
    "sca_valid_X.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training the Neural Network model using Keras (15 points)\n",
    "\n",
    "### Step 6.1\n",
    "Import the following libraries using import statements.\n",
    "<ul>\n",
    "    <li>keras (for deep learning) (Reference: <url>https://keras.io/</url>)\n",
    "        <ul>\n",
    "            <li>Sequential from keras.models</li>\n",
    "            <li>Dense from keras.layers</li>\n",
    "            <li>ModelCheckpoint from keras.callbacks</li>\n",
    "        </ul>\n",
    "    </li>    \n",
    "</ul>\n",
    "Note: Run a code cell by clicking on the cell and using the keyboard shortcut &lt;Shift&gt; + &lt;Enter&gt;.\n",
    "<br />\n",
    "Note: Tensorflow and Keras have to be installed first, see <strong>Step 0.1</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import print_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2\n",
    "- Build a neural network to learn from the given training set - trainData.\n",
    "(Reference: <a href=\"https://faroit.github.io/keras-docs/1.0.1/getting-started/sequential-model-guide/\">Here</a>)\n",
    "<ol>\n",
    "  <li>Initalizing a neural network using Sequential() function and name the returned object NN.</li>\n",
    "  <li>Adding the input layer and the hidden layer using add function of NN and Dense function.<br/>\n",
    "      Parameters of Dense function:\n",
    "      <ul>\n",
    "          <li>Set output_dim to 150: output_dim is the number of nodes we want to add to this layer.</li>\n",
    "          <li>kernel_initializer to 'normal': kernel_initializer is the initializer for the kernel weights matrix.</li>\n",
    "          <li>activation to 'relu': activation is the activation function of the node.</li>\n",
    "          <li>input_dim to the number of features: input_dim refers to the number of inputs, which is only needed for the first layer.<br />\n",
    "          You may use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html\">pandas.DataFrame.shape</a> function.\n",
    "          </li>\n",
    "      </ul>\n",
    "  </li>\n",
    "  <li>Adding the output layer using add function of NN and Dense function.<br/>\n",
    "      Parameters of Dense function:\n",
    "      <ul>\n",
    "          <li>Set output_dim to 1: output_dim is the number of nodes we want to add to this layer.</li>\n",
    "          <li>init to 'relu': init is the initialization of stochastic gradient decent.</li>\n",
    "          <li>activation to 'normal': activation is the activation function of the node.</li>\n",
    "      </ul>\n",
    "  </li>\n",
    "  <li>Prints a summary representation of our model by calling summary function of NN.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 67,951\n",
      "Trainable params: 67,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "model = Sequential()\n",
    "model.add(Dense(150, kernel_initializer='normal', activation='relu', input_dim=300))\n",
    "model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.3\n",
    "- Compile the neural network and start training\n",
    "<ol>\n",
    "  <li>Call <a href=\"https://keras.io/models/sequential/#compile\">compile()</a> function of NN to compile the neural network<br/>\n",
    "      Parameters of compile function:\n",
    "      <ul>\n",
    "          <li>loss to 'mean_squared_error': loss is a stochastic gradient decent depends on loss.</li>\n",
    "          <li>optimizer to 'Adam': optimizer is the algorithm that we want to use to find optimal set of weights. For details about 'Adam', please visit <a href=\"https://arxiv.org/abs/1412.6980v8\">here</a>.              \n",
    "          </li>\n",
    "          <li>metrics to ['mean_squared_error']: metrics is the metric(s) that we want to use to improve the performance of our neural network. In our case, accuracy is the metrics.</li>\n",
    "      </ul>\n",
    "  </li>\n",
    "  <li>Call <a href=\"https://keras.io/models/sequential/#fit\">fit()</a> function of NN to train the model on training data<br/>\n",
    "      Parameters of fit function:\n",
    "      <ul>\n",
    "          <li>Set x to X: x is the numpy array of training feature data.</li>\n",
    "          <li>Set y to Y: y is the numpy array of training target data.</li>\n",
    "          <li>Set batch_size to 32: batch_size is the number of samples per gradient update.</li>\n",
    "          <li>Set epochs to 500: epochs is the number of epochs to train the model.</li>\n",
    "      </ul>\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "1021/1021 [==============================] - 1s 501us/step - loss: 63.6788 - mean_squared_error: 63.6788\n",
      "Epoch 2/500\n",
      "1021/1021 [==============================] - 0s 109us/step - loss: 1.2659 - mean_squared_error: 1.2659\n",
      "Epoch 3/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.1415 - mean_squared_error: 0.1415\n",
      "Epoch 4/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0715 - mean_squared_error: 0.0715\n",
      "Epoch 5/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0545 - mean_squared_error: 0.0545\n",
      "Epoch 6/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0438 - mean_squared_error: 0.0438\n",
      "Epoch 7/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Epoch 8/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
      "Epoch 9/500\n",
      "1021/1021 [==============================] - 0s 123us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 10/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0225 - mean_squared_error: 0.0225\n",
      "Epoch 11/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0190 - mean_squared_error: 0.0190\n",
      "Epoch 12/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0164 - mean_squared_error: 0.0164\n",
      "Epoch 13/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
      "Epoch 14/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 15/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 16/500\n",
      "1021/1021 [==============================] - 0s 115us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 17/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 18/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 19/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 20/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 21/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 22/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 23/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 24/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 25/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 26/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 27/500\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.00 - 0s 93us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 28/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 29/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 30/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 31/500\n",
      "1021/1021 [==============================] - 0s 112us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 32/500\n",
      "1021/1021 [==============================] - 0s 121us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 33/500\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.00 - 0s 104us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 34/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 35/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 36/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 37/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 38/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 39/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 40/500\n",
      "1021/1021 [==============================] - 0s 107us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 41/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 42/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 43/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 44/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 45/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 46/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 47/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 48/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 49/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 50/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 51/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 52/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 53/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 54/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 55/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 56/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 57/500\n",
      "1021/1021 [==============================] - 0s 104us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 58/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 59/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 60/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 61/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 62/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 63/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 64/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 65/500\n",
      "1021/1021 [==============================] - 0s 122us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 66/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 67/500\n",
      "1021/1021 [==============================] - 0s 123us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 68/500\n",
      "1021/1021 [==============================] - 0s 120us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 105us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 70/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 71/500\n",
      "1021/1021 [==============================] - 0s 115us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 72/500\n",
      "1021/1021 [==============================] - 0s 123us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 73/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 74/500\n",
      "1021/1021 [==============================] - 0s 133us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 75/500\n",
      "1021/1021 [==============================] - 0s 123us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 76/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 77/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 78/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 79/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 80/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 81/500\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.00 - 0s 86us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 82/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 83/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 84/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 85/500\n",
      "1021/1021 [==============================] - 0s 80us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 86/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 87/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 88/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 89/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 90/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 91/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 92/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 93/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 94/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 95/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 96/500\n",
      "1021/1021 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 97/500\n",
      "1021/1021 [==============================] - 0s 80us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 98/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 99/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0017 - mean_squared_error: 0.0017 \n",
      "Epoch 100/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0014 - mean_squared_error: 0.0014 \n",
      "Epoch 101/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 102/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0017 - mean_squared_error: 0.0017 \n",
      "Epoch 103/500\n",
      "1021/1021 [==============================] - 0s 104us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 104/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 105/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 106/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 107/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 108/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 109/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 110/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 111/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 112/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 113/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 114/500\n",
      "1021/1021 [==============================] - 0s 119us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 115/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 116/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 117/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 118/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 119/500\n",
      "1021/1021 [==============================] - 0s 129us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 120/500\n",
      "1021/1021 [==============================] - 0s 151us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 121/500\n",
      "1021/1021 [==============================] - 0s 109us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 122/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 123/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 124/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 125/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 126/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 127/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 128/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 129/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 130/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 131/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 132/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 133/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 134/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 135/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 136/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0013 - mean_squared_error: 0.0013 \n",
      "Epoch 137/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 138/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 139/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 140/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 141/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 142/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 143/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 144/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 145/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 146/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 147/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 148/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 149/500\n",
      "1021/1021 [==============================] - 0s 139us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 150/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 151/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 152/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 153/500\n",
      "1021/1021 [==============================] - 0s 126us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 154/500\n",
      "1021/1021 [==============================] - 0s 140us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 155/500\n",
      "1021/1021 [==============================] - 0s 123us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 156/500\n",
      "1021/1021 [==============================] - 0s 128us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 157/500\n",
      "1021/1021 [==============================] - 0s 121us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 158/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 159/500\n",
      "1021/1021 [==============================] - 0s 124us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 160/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 161/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 162/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 163/500\n",
      "1021/1021 [==============================] - 0s 116us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 164/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 165/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 166/500\n",
      "1021/1021 [==============================] - 0s 185us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 167/500\n",
      "1021/1021 [==============================] - 0s 143us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 168/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 169/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 170/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 171/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 172/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 173/500\n",
      "1021/1021 [==============================] - 0s 130us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 174/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 175/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 176/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 177/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 178/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 179/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 180/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 181/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 182/500\n",
      "1021/1021 [==============================] - 0s 116us/step - loss: 0.0181 - mean_squared_error: 0.0181\n",
      "Epoch 183/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
      "Epoch 184/500\n",
      "1021/1021 [==============================] - 0s 80us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 185/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 186/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 187/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 188/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 189/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 190/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 191/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 192/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 193/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 194/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 195/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 196/500\n",
      "1021/1021 [==============================] - 0s 110us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 197/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 198/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 199/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 200/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 201/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 202/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 203/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 204/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 205/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 206/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 207/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 208/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 210/500\n",
      "1021/1021 [==============================] - 0s 106us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 211/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 212/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 213/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 214/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 215/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 216/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 217/500\n",
      "1021/1021 [==============================] - 0s 117us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 218/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 219/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 220/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 221/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 222/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0018 - mean_squared_error: 0.0018 \n",
      "Epoch 223/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 224/500\n",
      "1021/1021 [==============================] - 0s 105us/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 225/500\n",
      "1021/1021 [==============================] - 0s 121us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 226/500\n",
      "1021/1021 [==============================] - 0s 132us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 227/500\n",
      "1021/1021 [==============================] - 0s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 228/500\n",
      "1021/1021 [==============================] - 0s 116us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 229/500\n",
      "1021/1021 [==============================] - 0s 122us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 230/500\n",
      "1021/1021 [==============================] - 0s 116us/step - loss: 0.0012 - mean_squared_error: 0.00120s - loss: 0.0012 - mean_squared_error: 0.00\n",
      "Epoch 231/500\n",
      "1021/1021 [==============================] - 0s 104us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 232/500\n",
      "1021/1021 [==============================] - 0s 115us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 233/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 234/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 235/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 236/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 237/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 238/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 239/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0160 - mean_squared_error: 0.0160\n",
      "Epoch 240/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 241/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 242/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 243/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 244/500\n",
      "1021/1021 [==============================] - 0s 78us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 245/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0011 - mean_squared_error: 0.0011 \n",
      "Epoch 246/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0011 - mean_squared_error: 0.0011 \n",
      "Epoch 247/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 9.4149e-04 - mean_squared_error: 9.4149e-04\n",
      "Epoch 248/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 9.8842e-04 - mean_squared_error: 9.8842e-04\n",
      "Epoch 249/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 250/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 251/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 252/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 253/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 254/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 255/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 256/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 257/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 258/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 259/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 260/500\n",
      "1021/1021 [==============================] - 0s 79us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 261/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 262/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 263/500\n",
      "1021/1021 [==============================] - 0s 77us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 264/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 265/500\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.00 - 0s 94us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 266/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 267/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 268/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 9.9484e-04 - mean_squared_error: 9.9484e-04\n",
      "Epoch 269/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0013 - mean_squared_error: 0.0013 \n",
      "Epoch 270/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 271/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0022 - mean_squared_error: 0.0022 \n",
      "Epoch 272/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 273/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0022 - mean_squared_error: 0.0022 \n",
      "Epoch 274/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 275/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 276/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 277/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 278/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 279/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 280/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 281/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 282/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 283/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 284/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 285/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 286/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 287/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 288/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0015 - mean_squared_error: 0.0015- - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0011      \n",
      "Epoch 289/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 290/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 291/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 292/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 293/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 294/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 295/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 296/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 297/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 298/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 299/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 300/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 301/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 302/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 303/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 9.3567e-04 - mean_squared_error: 9.3567e-04\n",
      "Epoch 304/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 9.5574e-04 - mean_squared_error: 9.5574e-04\n",
      "Epoch 305/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 9.0677e-04 - mean_squared_error: 9.0677e-04\n",
      "Epoch 306/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0018 - mean_squared_error: 0.0018 \n",
      "Epoch 307/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 308/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 309/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 310/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0011 - mean_squared_error: 0.0011   \n",
      "Epoch 311/500\n",
      "1021/1021 [==============================] - 0s 112us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 312/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 9.7015e-04 - mean_squared_error: 9.7015e-04\n",
      "Epoch 313/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 314/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 315/500\n",
      "1021/1021 [==============================] - 0s 118us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 316/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 317/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 318/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
      "Epoch 319/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 320/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 321/500\n",
      "1021/1021 [==============================] - 0s 104us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 322/500\n",
      "1021/1021 [==============================] - 0s 107us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 323/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 324/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 325/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 326/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 327/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 328/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0013 - mean_squared_error: 0.0013 \n",
      "Epoch 329/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0011 - mean_squared_error: 0.0011   \n",
      "Epoch 330/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 331/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 332/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 9.3227e-04 - mean_squared_error: 9.3227e-04\n",
      "Epoch 333/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 9.0494e-04 - mean_squared_error: 9.0494e-04\n",
      "Epoch 334/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 7.4750e-04 - mean_squared_error: 7.4750e-04\n",
      "Epoch 335/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0014 - mean_squared_error: 0.0014   \n",
      "Epoch 336/500\n",
      "1021/1021 [==============================] - 0s 105us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 337/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0010 - mean_squared_error: 0.0010   \n",
      "Epoch 338/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 339/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 340/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 341/500\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.00 - 0s 91us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 342/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 343/500\n",
      "1021/1021 [==============================] - 0s 104us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 344/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 345/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 346/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 348/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 349/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 350/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 351/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 352/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 353/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 354/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0011 - mean_squared_error: 0.0011 \n",
      "Epoch 355/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0014 - mean_squared_error: 0.0014 \n",
      "Epoch 356/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 8.5577e-04 - mean_squared_error: 8.5577e-04\n",
      "Epoch 357/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 358/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0029 - mean_squared_error: 0.0029 \n",
      "Epoch 359/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 360/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 361/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 362/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 363/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 364/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 9.5068e-04 - mean_squared_error: 9.5068e-04\n",
      "Epoch 365/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 366/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 9.4940e-04 - mean_squared_error: 9.4940e-04\n",
      "Epoch 367/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0011 - mean_squared_error: 0.0011 \n",
      "Epoch 368/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0052 - mean_squared_error: 0.0052 \n",
      "Epoch 369/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 370/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 371/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0014 - mean_squared_error: 0.0014 \n",
      "Epoch 372/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 373/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 374/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 375/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 376/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 377/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 378/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0017 - mean_squared_error: 0.0017 \n",
      "Epoch 379/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0013 - mean_squared_error: 0.0013 \n",
      "Epoch 380/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 381/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 382/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0021 - mean_squared_error: 0.0021 \n",
      "Epoch 383/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 384/500\n",
      "1021/1021 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.00 - 0s 86us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 385/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 386/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 387/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 388/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 389/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 4.8239e-04 - mean_squared_error: 4.8239e-04\n",
      "Epoch 390/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 6.2330e-04 - mean_squared_error: 6.2330e-04\n",
      "Epoch 391/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 392/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 393/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 7.0535e-04 - mean_squared_error: 7.0535e-04\n",
      "Epoch 394/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0014 - mean_squared_error: 0.0014 \n",
      "Epoch 395/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 396/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0024 - mean_squared_error: 0.0024 \n",
      "Epoch 397/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 398/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 399/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 400/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 401/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 402/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 403/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 404/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 405/500\n",
      "1021/1021 [==============================] - 0s 81us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 406/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0023 - mean_squared_error: 0.00230s - loss: 0.0024 - mean_squared_error: 0.00\n",
      "Epoch 407/500\n",
      "1021/1021 [==============================] - 0s 116us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 408/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 409/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 410/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 411/500\n",
      "1021/1021 [==============================] - 0s 83us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 412/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0011 - mean_squared_error: 0.0011 \n",
      "Epoch 413/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 414/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 7.3696e-04 - mean_squared_error: 7.3696e-04\n",
      "Epoch 415/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0012 - mean_squared_error: 0.0012 \n",
      "Epoch 416/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 417/500\n",
      "1021/1021 [==============================] - 0s 111us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 418/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 419/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 420/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0109 - mean_squared_error: 0.0109 \n",
      "Epoch 421/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 422/500\n",
      "1021/1021 [==============================] - 0s 115us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 423/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 424/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 425/500\n",
      "1021/1021 [==============================] - 0s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 \n",
      "Epoch 426/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 9.9569e-04 - mean_squared_error: 9.9569e-04\n",
      "Epoch 427/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0011 - mean_squared_error: 0.0011   \n",
      "Epoch 428/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 7.3586e-04 - mean_squared_error: 7.3586e-04\n",
      "Epoch 429/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 6.0776e-04 - mean_squared_error: 6.0776e-04\n",
      "Epoch 430/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 5.5231e-04 - mean_squared_error: 5.5231e-04\n",
      "Epoch 431/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 7.3984e-04 - mean_squared_error: 7.3984e-04\n",
      "Epoch 432/500\n",
      "1021/1021 [==============================] - 0s 86us/step - loss: 5.3257e-04 - mean_squared_error: 5.3257e-04\n",
      "Epoch 433/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 8.4095e-04 - mean_squared_error: 8.4095e-04ss: 6.9699e-04 - mean_squared_error: 6.9699e-\n",
      "Epoch 434/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 435/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 436/500\n",
      "1021/1021 [==============================] - 0s 93us/step - loss: 6.3579e-04 - mean_squared_error: 6.3579e-04\n",
      "Epoch 437/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 438/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 439/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 440/500\n",
      "1021/1021 [==============================] - 0s 95us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 441/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 442/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 443/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0014 - mean_squared_error: 0.0014 \n",
      "Epoch 444/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 0.0015 - mean_squared_error: 0.0015 \n",
      "Epoch 445/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 446/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 447/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 448/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 449/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 450/500\n",
      "1021/1021 [==============================] - 0s 102us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 451/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 452/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0013 - mean_squared_error: 0.0013   \n",
      "Epoch 453/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 454/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 455/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 5.5551e-04 - mean_squared_error: 5.5551e-04\n",
      "Epoch 456/500\n",
      "1021/1021 [==============================] - 0s 91us/step - loss: 8.9817e-04 - mean_squared_error: 8.9817e-04\n",
      "Epoch 457/500\n",
      "1021/1021 [==============================] - 0s 88us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 458/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 9.0781e-04 - mean_squared_error: 9.0781e-04\n",
      "Epoch 459/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0020 - mean_squared_error: 0.0020 \n",
      "Epoch 460/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 461/500\n",
      "1021/1021 [==============================] - 0s 104us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 462/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 463/500\n",
      "1021/1021 [==============================] - 0s 78us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 464/500\n",
      "1021/1021 [==============================] - 0s 84us/step - loss: 0.0038 - mean_squared_error: 0.0038 \n",
      "Epoch 465/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 466/500\n",
      "1021/1021 [==============================] - 0s 82us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 467/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 468/500\n",
      "1021/1021 [==============================] - 0s 118us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 469/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 470/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 471/500\n",
      "1021/1021 [==============================] - 0s 108us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 472/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 473/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 474/500\n",
      "1021/1021 [==============================] - 0s 94us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 475/500\n",
      "1021/1021 [==============================] - 0s 112us/step - loss: 6.9625e-04 - mean_squared_error: 6.9625e-04\n",
      "Epoch 476/500\n",
      "1021/1021 [==============================] - 0s 105us/step - loss: 0.0011 - mean_squared_error: 0.0011  \n",
      "Epoch 477/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 478/500\n",
      "1021/1021 [==============================] - 0s 111us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 479/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0010 - mean_squared_error: 0.0010 \n",
      "Epoch 480/500\n",
      "1021/1021 [==============================] - 0s 100us/step - loss: 5.6621e-04 - mean_squared_error: 5.6621e-04\n",
      "Epoch 481/500\n",
      "1021/1021 [==============================] - 0s 99us/step - loss: 0.0014 - mean_squared_error: 0.0014 \n",
      "Epoch 482/500\n",
      "1021/1021 [==============================] - 0s 113us/step - loss: 8.0187e-04 - mean_squared_error: 8.0187e-04\n",
      "Epoch 483/500\n",
      "1021/1021 [==============================] - 0s 114us/step - loss: 6.6986e-04 - mean_squared_error: 6.6986e-04\n",
      "Epoch 484/500\n",
      "1021/1021 [==============================] - 0s 118us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 0s 101us/step - loss: 7.3668e-04 - mean_squared_error: 7.3668e-04\n",
      "Epoch 486/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 8.7611e-04 - mean_squared_error: 8.7611e-04\n",
      "Epoch 487/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0012 - mean_squared_error: 0.0012   \n",
      "Epoch 488/500\n",
      "1021/1021 [==============================] - 0s 97us/step - loss: 0.0011 - mean_squared_error: 0.0011 \n",
      "Epoch 489/500\n",
      "1021/1021 [==============================] - 0s 101us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 490/500\n",
      "1021/1021 [==============================] - 0s 103us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 491/500\n",
      "1021/1021 [==============================] - 0s 98us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 492/500\n",
      "1021/1021 [==============================] - 0s 89us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 493/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 494/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 495/500\n",
      "1021/1021 [==============================] - 0s 92us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 496/500\n",
      "1021/1021 [==============================] - 0s 85us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 497/500\n",
      "1021/1021 [==============================] - 0s 96us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 498/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 499/500\n",
      "1021/1021 [==============================] - 0s 87us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 500/500\n",
      "1021/1021 [==============================] - 0s 77us/step - loss: 0.0014 - mean_squared_error: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f19cd55048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your statements here\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_squared_error'])\n",
    "model.fit(sca_train_X, Y_train, batch_size=32, epochs=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.4 \n",
    "Evaluate the model with Validation dataset\n",
    "\n",
    "<ol>\n",
    "<li>Evaluate the model with the validation data using the <a href=\"https://keras.io/models/sequential/#evaluate\">evaluate()</a> function.\n",
    "The evaluate function returns the loss value and metrics values for the model in test mode.\n",
    "</li>\n",
    "<li>Compute the RMSE by otaining the square-root of the MSE using <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.sqrt.html\">numpy.sqrt()</a> function.</li>\n",
    "<li>Print the RMSE.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 142us/step\n",
      "0.2531560173472991\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "loss, metrics = model.evaluate(sca_valid_X, Y_valid, batch_size = 32)\n",
    "rmse = np.sqrt(loss)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Predict the testing data (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.1  Load the testing data (house-test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statement here\n",
    "test_data = pd.read_csv('house-test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.2: Prepare the testing data\n",
    "\n",
    "Steps for preprocessing the testing data:\n",
    "<ol>\n",
    "<li>Exploring the features.</li>\n",
    "<li>Cleaning data: Handling missing values</li>\n",
    "<li><del>Creating new features and </del>dropping redundant features.</li>\n",
    "<li>Transforming data.</li>\n",
    "</ol>\n",
    "\n",
    "You may refer to Assignment 1 and also Step 1 above for reference.\n",
    "(You may add multiple cells below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.1\n",
    "Evaluate the data quality & perform missing values assessment using isnull function (<a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html\">pandas.isnull</a>) and sum function (<a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html\">pandas.DataFrame.sum</a>) of pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            4\n",
       "LotFrontage       227\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1352\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           2\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         1\n",
       "Exterior2nd         1\n",
       "MasVnrType         16\n",
       "MasVnrArea         15\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         1\n",
       "TotRmsAbvGrd        0\n",
       "Functional          2\n",
       "Fireplaces          0\n",
       "FireplaceQu       730\n",
       "GarageType         76\n",
       "GarageYrBlt        78\n",
       "GarageFinish       78\n",
       "GarageCars          1\n",
       "GarageArea          1\n",
       "GarageQual         78\n",
       "GarageCond         78\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1456\n",
       "Fence            1169\n",
       "MiscFeature      1408\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            1\n",
       "SaleCondition       0\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your statements here\n",
    "test_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.2 Handling Not Really NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "test_data[\"Alley\"].fillna(\"None\", inplace=True)\n",
    "test_data[\"BsmtQual\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"BsmtCond\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"BsmtExposure\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"BsmtFinType1\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"BsmtFinType2\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"Fence\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"FireplaceQu\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"Functional\"].fillna(\"Typ\", inplace=True)\n",
    "test_data[\"GarageType\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"GarageFinish\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"GarageQual\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"GarageCond\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"PoolQC\"].fillna(\"No\", inplace=True)\n",
    "test_data[\"MiscFeature\"].fillna(\"No\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.3 Use mean / median to impute the missing values of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "ltf_mean = test_data[\"LotFrontage\"].mean(skipna=True)\n",
    "test_data[\"LotFrontage\"].fillna(ltf_mean, inplace=True)\n",
    "pa_mean = test_data[\"PoolArea\"].mean(skipna=True)\n",
    "test_data[\"PoolArea\"].fillna(pa_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.4 Use the most common values to impute the missing values of the features features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here, you may add more code cells and markup cells if necessory\n",
    "test_data[\"MasVnrType\"].fillna(\"None\", inplace=True)\n",
    "test_data[\"MasVnrArea\"].fillna(\"0\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.5: Drop a certain instance with missing value if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "columns = list(test_data.columns)\n",
    "for col in columns:\n",
    "    if test_data[col].isnull().sum()>0:\n",
    "        test_data = test_data.drop(test_data.loc[test_data[col].isnull()].index)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.6: Drop certain features if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "test_data = test_data.drop(['GarageYrBlt'], axis=1)\n",
    "test_data = test_data.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.7: Change the type of certain feature(s) if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "test_data['MasVnrArea'] = test_data['MasVnrArea'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.8: Normalize the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "numeric_feats = test_data.dtypes[test_data.dtypes != \"object\"].index\n",
    "skewed_feats = test_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "\n",
    "for feat in skewed_feats.index:\n",
    "    test_data[feat] = np.log1p(test_data[feat])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.9: Convert categorical features into dummy/indicator features\n",
    "Note: You may need to align with the training features data using <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.align.html\">pandas.DataFrame.align()</a> function.\n",
    "\n",
    "Review the converted testing data by using pandas.DataFrame.head() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>9.360741</td>\n",
       "      <td>5</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.150603</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>9.565775</td>\n",
       "      <td>6</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>4.691348</td>\n",
       "      <td>6.828712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>9.534668</td>\n",
       "      <td>5</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.674561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.369448</td>\n",
       "      <td>9.208238</td>\n",
       "      <td>6</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>6.401917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.795791</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>8.518392</td>\n",
       "      <td>8</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.575949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.330733</td>\n",
       "      <td>9.210440</td>\n",
       "      <td>6</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.242482</td>\n",
       "      <td>8.984819</td>\n",
       "      <td>6</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1992</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.841615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>9.036344</td>\n",
       "      <td>6</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.454347</td>\n",
       "      <td>9.227886</td>\n",
       "      <td>7</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.458338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>9.036106</td>\n",
       "      <td>4</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.690842</td>\n",
       "      <td>4.369448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    3.044522     4.394449  9.360741            5     1.945910       1961   \n",
       "1    3.044522     4.406719  9.565775            6     1.945910       1958   \n",
       "2    4.110874     4.317488  9.534668            5     1.791759       1997   \n",
       "3    4.110874     4.369448  9.208238            6     1.945910       1998   \n",
       "4    4.795791     3.784190  8.518392            8     1.791759       1992   \n",
       "5    4.110874     4.330733  9.210440            6     1.791759       1993   \n",
       "6    3.044522     4.242482  8.984819            6     2.079442       1992   \n",
       "7    4.110874     4.158883  9.036344            6     1.791759       1998   \n",
       "8    3.044522     4.454347  9.227886            7     1.791759       1990   \n",
       "9    3.044522     4.262680  9.036106            4     1.791759       1970   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2          ...            \\\n",
       "0          1961    0.000000    6.150603    4.976734          ...             \n",
       "1          1958    4.691348    6.828712    0.000000          ...             \n",
       "2          1998    0.000000    6.674561    0.000000          ...             \n",
       "3          1998    3.044522    6.401917    0.000000          ...             \n",
       "4          1992    0.000000    5.575949    0.000000          ...             \n",
       "5          1994    0.000000    0.000000    0.000000          ...             \n",
       "6          2007    0.000000    6.841615    0.000000          ...             \n",
       "7          1998    0.000000    0.000000    0.000000          ...             \n",
       "8          1990    0.000000    6.458338    0.000000          ...             \n",
       "9          1970    0.000000    6.690842    4.369448          ...             \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "5               0             0             0            1   \n",
       "6               0             0             0            1   \n",
       "7               0             0             0            1   \n",
       "8               0             0             0            1   \n",
       "9               0             0             0            1   \n",
       "\n",
       "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      0                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "5                      0                      0                     0   \n",
       "6                      0                      0                     0   \n",
       "7                      0                      0                     0   \n",
       "8                      0                      0                     0   \n",
       "9                      0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     1                      0  \n",
       "4                     0                     1                      0  \n",
       "5                     0                     1                      0  \n",
       "6                     0                     1                      0  \n",
       "7                     0                     1                      0  \n",
       "8                     0                     1                      0  \n",
       "9                     0                     1                      0  \n",
       "\n",
       "[10 rows x 272 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your statements here\n",
    "\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2.10 Any additional preprocessing steps needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>MSZoning_C (all)</th>\n",
       "      <th>MSZoning_FV</th>\n",
       "      <th>MSZoning_RH</th>\n",
       "      <th>MSZoning_RL</th>\n",
       "      <th>MSZoning_RM</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "      <th>Alley_Grvl</th>\n",
       "      <th>Alley_None</th>\n",
       "      <th>Alley_Pave</th>\n",
       "      <th>LotShape_IR1</th>\n",
       "      <th>LotShape_IR2</th>\n",
       "      <th>LotShape_IR3</th>\n",
       "      <th>LotShape_Reg</th>\n",
       "      <th>LandContour_Bnk</th>\n",
       "      <th>LandContour_HLS</th>\n",
       "      <th>LandContour_Low</th>\n",
       "      <th>LandContour_Lvl</th>\n",
       "      <th>Utilities_AllPub</th>\n",
       "      <th>LotConfig_Corner</th>\n",
       "      <th>LotConfig_CulDSac</th>\n",
       "      <th>LotConfig_FR2</th>\n",
       "      <th>LotConfig_FR3</th>\n",
       "      <th>LotConfig_Inside</th>\n",
       "      <th>LandSlope_Gtl</th>\n",
       "      <th>LandSlope_Mod</th>\n",
       "      <th>LandSlope_Sev</th>\n",
       "      <th>Neighborhood_Blmngtn</th>\n",
       "      <th>Neighborhood_Blueste</th>\n",
       "      <th>Neighborhood_BrDale</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_ClearCr</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_IDOTRR</th>\n",
       "      <th>Neighborhood_MeadowV</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NPkVill</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NoRidge</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_SWISU</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <th>Neighborhood_Timber</th>\n",
       "      <th>Neighborhood_Veenker</th>\n",
       "      <th>Condition1_Artery</th>\n",
       "      <th>Condition1_Feedr</th>\n",
       "      <th>Condition1_Norm</th>\n",
       "      <th>Condition1_PosA</th>\n",
       "      <th>Condition1_PosN</th>\n",
       "      <th>Condition1_RRAe</th>\n",
       "      <th>Condition1_RRAn</th>\n",
       "      <th>Condition1_RRNe</th>\n",
       "      <th>Condition1_RRNn</th>\n",
       "      <th>Condition2_Artery</th>\n",
       "      <th>Condition2_Feedr</th>\n",
       "      <th>Condition2_Norm</th>\n",
       "      <th>Condition2_PosA</th>\n",
       "      <th>Condition2_PosN</th>\n",
       "      <th>BldgType_1Fam</th>\n",
       "      <th>BldgType_2fmCon</th>\n",
       "      <th>BldgType_Duplex</th>\n",
       "      <th>BldgType_Twnhs</th>\n",
       "      <th>BldgType_TwnhsE</th>\n",
       "      <th>HouseStyle_1.5Fin</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>RoofStyle_Flat</th>\n",
       "      <th>RoofStyle_Gable</th>\n",
       "      <th>RoofStyle_Gambrel</th>\n",
       "      <th>RoofStyle_Hip</th>\n",
       "      <th>RoofStyle_Mansard</th>\n",
       "      <th>RoofStyle_Shed</th>\n",
       "      <th>RoofMatl_CompShg</th>\n",
       "      <th>RoofMatl_Tar&amp;Grv</th>\n",
       "      <th>RoofMatl_WdShake</th>\n",
       "      <th>RoofMatl_WdShngl</th>\n",
       "      <th>Exterior1st_AsbShng</th>\n",
       "      <th>Exterior1st_BrkComm</th>\n",
       "      <th>Exterior1st_BrkFace</th>\n",
       "      <th>Exterior1st_CemntBd</th>\n",
       "      <th>Exterior1st_HdBoard</th>\n",
       "      <th>Exterior1st_MetalSd</th>\n",
       "      <th>Exterior1st_Plywood</th>\n",
       "      <th>Exterior1st_Stucco</th>\n",
       "      <th>Exterior1st_VinylSd</th>\n",
       "      <th>Exterior1st_Wd Sdng</th>\n",
       "      <th>Exterior1st_WdShing</th>\n",
       "      <th>Exterior2nd_AsbShng</th>\n",
       "      <th>Exterior2nd_Brk Cmn</th>\n",
       "      <th>Exterior2nd_BrkFace</th>\n",
       "      <th>Exterior2nd_CmentBd</th>\n",
       "      <th>Exterior2nd_HdBoard</th>\n",
       "      <th>Exterior2nd_ImStucc</th>\n",
       "      <th>Exterior2nd_MetalSd</th>\n",
       "      <th>Exterior2nd_Plywood</th>\n",
       "      <th>Exterior2nd_Stone</th>\n",
       "      <th>Exterior2nd_Stucco</th>\n",
       "      <th>Exterior2nd_VinylSd</th>\n",
       "      <th>Exterior2nd_Wd Sdng</th>\n",
       "      <th>Exterior2nd_Wd Shng</th>\n",
       "      <th>MasVnrType_BrkCmn</th>\n",
       "      <th>MasVnrType_BrkFace</th>\n",
       "      <th>MasVnrType_None</th>\n",
       "      <th>MasVnrType_Stone</th>\n",
       "      <th>ExterQual_Ex</th>\n",
       "      <th>ExterQual_Fa</th>\n",
       "      <th>ExterQual_Gd</th>\n",
       "      <th>ExterQual_TA</th>\n",
       "      <th>ExterCond_Ex</th>\n",
       "      <th>ExterCond_Fa</th>\n",
       "      <th>ExterCond_Gd</th>\n",
       "      <th>ExterCond_Po</th>\n",
       "      <th>ExterCond_TA</th>\n",
       "      <th>Foundation_BrkTil</th>\n",
       "      <th>Foundation_CBlock</th>\n",
       "      <th>Foundation_PConc</th>\n",
       "      <th>Foundation_Slab</th>\n",
       "      <th>Foundation_Stone</th>\n",
       "      <th>Foundation_Wood</th>\n",
       "      <th>BsmtQual_Ex</th>\n",
       "      <th>BsmtQual_Fa</th>\n",
       "      <th>BsmtQual_Gd</th>\n",
       "      <th>BsmtQual_No</th>\n",
       "      <th>BsmtQual_TA</th>\n",
       "      <th>BsmtCond_Fa</th>\n",
       "      <th>BsmtCond_Gd</th>\n",
       "      <th>BsmtCond_No</th>\n",
       "      <th>BsmtCond_Po</th>\n",
       "      <th>BsmtCond_TA</th>\n",
       "      <th>BsmtExposure_Av</th>\n",
       "      <th>BsmtExposure_Gd</th>\n",
       "      <th>BsmtExposure_Mn</th>\n",
       "      <th>BsmtExposure_No</th>\n",
       "      <th>BsmtFinType1_ALQ</th>\n",
       "      <th>BsmtFinType1_BLQ</th>\n",
       "      <th>BsmtFinType1_GLQ</th>\n",
       "      <th>BsmtFinType1_LwQ</th>\n",
       "      <th>BsmtFinType1_No</th>\n",
       "      <th>BsmtFinType1_Rec</th>\n",
       "      <th>BsmtFinType1_Unf</th>\n",
       "      <th>BsmtFinType2_ALQ</th>\n",
       "      <th>BsmtFinType2_BLQ</th>\n",
       "      <th>BsmtFinType2_GLQ</th>\n",
       "      <th>BsmtFinType2_LwQ</th>\n",
       "      <th>BsmtFinType2_No</th>\n",
       "      <th>BsmtFinType2_Rec</th>\n",
       "      <th>BsmtFinType2_Unf</th>\n",
       "      <th>Heating_GasA</th>\n",
       "      <th>Heating_GasW</th>\n",
       "      <th>Heating_Wall</th>\n",
       "      <th>HeatingQC_Ex</th>\n",
       "      <th>HeatingQC_Fa</th>\n",
       "      <th>HeatingQC_Gd</th>\n",
       "      <th>HeatingQC_Po</th>\n",
       "      <th>HeatingQC_TA</th>\n",
       "      <th>CentralAir_N</th>\n",
       "      <th>CentralAir_Y</th>\n",
       "      <th>Electrical_FuseA</th>\n",
       "      <th>Electrical_FuseF</th>\n",
       "      <th>Electrical_FuseP</th>\n",
       "      <th>Electrical_SBrkr</th>\n",
       "      <th>KitchenQual_Ex</th>\n",
       "      <th>KitchenQual_Fa</th>\n",
       "      <th>KitchenQual_Gd</th>\n",
       "      <th>KitchenQual_TA</th>\n",
       "      <th>Functional_Maj1</th>\n",
       "      <th>Functional_Maj2</th>\n",
       "      <th>Functional_Min1</th>\n",
       "      <th>Functional_Min2</th>\n",
       "      <th>Functional_Mod</th>\n",
       "      <th>Functional_Typ</th>\n",
       "      <th>FireplaceQu_Ex</th>\n",
       "      <th>FireplaceQu_Fa</th>\n",
       "      <th>FireplaceQu_Gd</th>\n",
       "      <th>FireplaceQu_No</th>\n",
       "      <th>FireplaceQu_Po</th>\n",
       "      <th>FireplaceQu_TA</th>\n",
       "      <th>GarageType_2Types</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_Basment</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_CarPort</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "      <th>GarageFinish_Fin</th>\n",
       "      <th>GarageFinish_RFn</th>\n",
       "      <th>GarageFinish_Unf</th>\n",
       "      <th>GarageQual_Fa</th>\n",
       "      <th>GarageQual_Gd</th>\n",
       "      <th>GarageQual_Po</th>\n",
       "      <th>GarageQual_TA</th>\n",
       "      <th>GarageCond_Ex</th>\n",
       "      <th>GarageCond_Fa</th>\n",
       "      <th>GarageCond_Gd</th>\n",
       "      <th>GarageCond_Po</th>\n",
       "      <th>GarageCond_TA</th>\n",
       "      <th>PavedDrive_N</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>PoolQC_Ex</th>\n",
       "      <th>PoolQC_Gd</th>\n",
       "      <th>PoolQC_No</th>\n",
       "      <th>Fence_GdPrv</th>\n",
       "      <th>Fence_GdWo</th>\n",
       "      <th>Fence_MnPrv</th>\n",
       "      <th>Fence_MnWw</th>\n",
       "      <th>Fence_No</th>\n",
       "      <th>MiscFeature_Gar2</th>\n",
       "      <th>MiscFeature_No</th>\n",
       "      <th>MiscFeature_Othr</th>\n",
       "      <th>MiscFeature_Shed</th>\n",
       "      <th>SaleType_COD</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.00000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.00000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.00000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.00000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.806538</td>\n",
       "      <td>4.200201</td>\n",
       "      <td>9.085644</td>\n",
       "      <td>6.174927</td>\n",
       "      <td>1.871282</td>\n",
       "      <td>1973.043003</td>\n",
       "      <td>1984.373178</td>\n",
       "      <td>2.131305</td>\n",
       "      <td>4.361030</td>\n",
       "      <td>0.739250</td>\n",
       "      <td>5.633517</td>\n",
       "      <td>6.769547</td>\n",
       "      <td>7.009270</td>\n",
       "      <td>2.799118</td>\n",
       "      <td>0.049945</td>\n",
       "      <td>7.264022</td>\n",
       "      <td>0.444606</td>\n",
       "      <td>0.044754</td>\n",
       "      <td>1.582362</td>\n",
       "      <td>0.385569</td>\n",
       "      <td>2.841108</td>\n",
       "      <td>0.705941</td>\n",
       "      <td>1.981069</td>\n",
       "      <td>0.397003</td>\n",
       "      <td>1.867347</td>\n",
       "      <td>6.143472</td>\n",
       "      <td>2.530973</td>\n",
       "      <td>2.405970</td>\n",
       "      <td>0.774055</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.515526</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.221003</td>\n",
       "      <td>6.129009</td>\n",
       "      <td>2007.765306</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.779883</td>\n",
       "      <td>0.154519</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.997085</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.931487</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.345481</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.625364</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>0.050292</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172012</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.736152</td>\n",
       "      <td>0.954810</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.034257</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>0.061953</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.044461</td>\n",
       "      <td>0.155977</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>0.064869</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.069971</td>\n",
       "      <td>0.01895</td>\n",
       "      <td>0.024781</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.862974</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.839650</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.080904</td>\n",
       "      <td>0.105685</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.51312</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.296647</td>\n",
       "      <td>0.028426</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.800292</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.185131</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.024781</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.157434</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>0.077259</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.360787</td>\n",
       "      <td>0.131924</td>\n",
       "      <td>0.01895</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.140671</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.161808</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.359329</td>\n",
       "      <td>0.128280</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.311224</td>\n",
       "      <td>0.595481</td>\n",
       "      <td>0.087464</td>\n",
       "      <td>0.040087</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.352770</td>\n",
       "      <td>0.599125</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.019679</td>\n",
       "      <td>0.104956</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.868076</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.412536</td>\n",
       "      <td>0.462828</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.099854</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.416910</td>\n",
       "      <td>0.023324</td>\n",
       "      <td>0.429300</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.039359</td>\n",
       "      <td>0.024052</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.900875</td>\n",
       "      <td>0.136297</td>\n",
       "      <td>0.101312</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>0.675656</td>\n",
       "      <td>0.147230</td>\n",
       "      <td>0.086006</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>0.108601</td>\n",
       "      <td>0.273324</td>\n",
       "      <td>0.023324</td>\n",
       "      <td>0.024781</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>0.849125</td>\n",
       "      <td>0.993440</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.529155</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.159621</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.284985</td>\n",
       "      <td>0.048105</td>\n",
       "      <td>0.951895</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.925656</td>\n",
       "      <td>0.075073</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.399417</td>\n",
       "      <td>0.508746</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.938047</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.259475</td>\n",
       "      <td>0.475219</td>\n",
       "      <td>0.01895</td>\n",
       "      <td>0.202624</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.618076</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.281341</td>\n",
       "      <td>0.267493</td>\n",
       "      <td>0.283528</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.938047</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.026968</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.963557</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.039359</td>\n",
       "      <td>0.118805</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.798834</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.967201</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.083819</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.861516</td>\n",
       "      <td>0.053207</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.831633</td>\n",
       "      <td>0.086006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.322355</td>\n",
       "      <td>0.488516</td>\n",
       "      <td>1.397616</td>\n",
       "      <td>0.157738</td>\n",
       "      <td>29.505436</td>\n",
       "      <td>20.789679</td>\n",
       "      <td>2.637444</td>\n",
       "      <td>2.922026</td>\n",
       "      <td>1.949698</td>\n",
       "      <td>1.824946</td>\n",
       "      <td>1.082098</td>\n",
       "      <td>0.324701</td>\n",
       "      <td>3.266460</td>\n",
       "      <td>0.536193</td>\n",
       "      <td>0.310957</td>\n",
       "      <td>0.525631</td>\n",
       "      <td>0.171360</td>\n",
       "      <td>0.553283</td>\n",
       "      <td>0.506006</td>\n",
       "      <td>0.802695</td>\n",
       "      <td>0.074718</td>\n",
       "      <td>0.194997</td>\n",
       "      <td>0.394243</td>\n",
       "      <td>0.673483</td>\n",
       "      <td>0.387257</td>\n",
       "      <td>2.598820</td>\n",
       "      <td>2.151033</td>\n",
       "      <td>1.773732</td>\n",
       "      <td>0.490089</td>\n",
       "      <td>1.546026</td>\n",
       "      <td>0.391644</td>\n",
       "      <td>1.215288</td>\n",
       "      <td>2.711534</td>\n",
       "      <td>1.298158</td>\n",
       "      <td>0.071272</td>\n",
       "      <td>0.225973</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.414476</td>\n",
       "      <td>0.361577</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.201287</td>\n",
       "      <td>0.252716</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>0.475698</td>\n",
       "      <td>0.157726</td>\n",
       "      <td>0.060280</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.187458</td>\n",
       "      <td>0.218626</td>\n",
       "      <td>0.122812</td>\n",
       "      <td>0.302812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377528</td>\n",
       "      <td>0.235782</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.440879</td>\n",
       "      <td>0.207795</td>\n",
       "      <td>0.202938</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>0.076165</td>\n",
       "      <td>0.100535</td>\n",
       "      <td>0.181954</td>\n",
       "      <td>0.104025</td>\n",
       "      <td>0.279395</td>\n",
       "      <td>0.191026</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>0.241159</td>\n",
       "      <td>0.168301</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.206191</td>\n",
       "      <td>0.362966</td>\n",
       "      <td>0.100535</td>\n",
       "      <td>0.201287</td>\n",
       "      <td>0.146299</td>\n",
       "      <td>0.246384</td>\n",
       "      <td>0.268251</td>\n",
       "      <td>0.113828</td>\n",
       "      <td>0.224528</td>\n",
       "      <td>0.202938</td>\n",
       "      <td>0.255191</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>0.225973</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>0.119897</td>\n",
       "      <td>0.100535</td>\n",
       "      <td>0.131146</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.071272</td>\n",
       "      <td>0.100535</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.367064</td>\n",
       "      <td>0.119897</td>\n",
       "      <td>0.170328</td>\n",
       "      <td>0.183810</td>\n",
       "      <td>0.272787</td>\n",
       "      <td>0.307546</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.50001</td>\n",
       "      <td>0.085093</td>\n",
       "      <td>0.456946</td>\n",
       "      <td>0.166246</td>\n",
       "      <td>0.209384</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.399927</td>\n",
       "      <td>0.085093</td>\n",
       "      <td>0.388546</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.076165</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.116904</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>0.201287</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>0.365709</td>\n",
       "      <td>0.267100</td>\n",
       "      <td>0.104025</td>\n",
       "      <td>0.480404</td>\n",
       "      <td>0.338532</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>0.104025</td>\n",
       "      <td>0.119897</td>\n",
       "      <td>0.202938</td>\n",
       "      <td>0.347808</td>\n",
       "      <td>0.060280</td>\n",
       "      <td>0.368408</td>\n",
       "      <td>0.281549</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.110662</td>\n",
       "      <td>0.479979</td>\n",
       "      <td>0.334523</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>0.076165</td>\n",
       "      <td>0.463163</td>\n",
       "      <td>0.490978</td>\n",
       "      <td>0.282616</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>0.478006</td>\n",
       "      <td>0.490254</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.138946</td>\n",
       "      <td>0.306609</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.338532</td>\n",
       "      <td>0.309408</td>\n",
       "      <td>0.492470</td>\n",
       "      <td>0.498798</td>\n",
       "      <td>0.113828</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.299915</td>\n",
       "      <td>0.172328</td>\n",
       "      <td>0.493227</td>\n",
       "      <td>0.150984</td>\n",
       "      <td>0.495157</td>\n",
       "      <td>0.183810</td>\n",
       "      <td>0.194518</td>\n",
       "      <td>0.153268</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.298939</td>\n",
       "      <td>0.343229</td>\n",
       "      <td>0.301851</td>\n",
       "      <td>0.281549</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.354465</td>\n",
       "      <td>0.280475</td>\n",
       "      <td>0.461049</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>0.146299</td>\n",
       "      <td>0.311251</td>\n",
       "      <td>0.445828</td>\n",
       "      <td>0.150984</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>0.119897</td>\n",
       "      <td>0.170328</td>\n",
       "      <td>0.146299</td>\n",
       "      <td>0.187458</td>\n",
       "      <td>0.358057</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.076165</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.499331</td>\n",
       "      <td>0.157726</td>\n",
       "      <td>0.366388</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.451572</td>\n",
       "      <td>0.214066</td>\n",
       "      <td>0.214066</td>\n",
       "      <td>0.235782</td>\n",
       "      <td>0.113828</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.262426</td>\n",
       "      <td>0.263605</td>\n",
       "      <td>0.128432</td>\n",
       "      <td>0.489957</td>\n",
       "      <td>0.500106</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.146299</td>\n",
       "      <td>0.110662</td>\n",
       "      <td>0.241159</td>\n",
       "      <td>0.116904</td>\n",
       "      <td>0.170328</td>\n",
       "      <td>0.438507</td>\n",
       "      <td>0.499568</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.402101</td>\n",
       "      <td>0.110662</td>\n",
       "      <td>0.486035</td>\n",
       "      <td>0.110662</td>\n",
       "      <td>0.257633</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.449817</td>\n",
       "      <td>0.442813</td>\n",
       "      <td>0.450875</td>\n",
       "      <td>0.497571</td>\n",
       "      <td>0.224528</td>\n",
       "      <td>0.085093</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.241159</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.162049</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.187458</td>\n",
       "      <td>0.235782</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.273904</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.201287</td>\n",
       "      <td>0.194518</td>\n",
       "      <td>0.323677</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.401018</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.178175</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.168301</td>\n",
       "      <td>0.170328</td>\n",
       "      <td>0.076165</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.277218</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>0.345533</td>\n",
       "      <td>0.224528</td>\n",
       "      <td>0.060280</td>\n",
       "      <td>0.085093</td>\n",
       "      <td>0.133801</td>\n",
       "      <td>0.374329</td>\n",
       "      <td>0.280475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>7.303170</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.011267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.011267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>8.915801</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1955.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.401549</td>\n",
       "      <td>6.689909</td>\n",
       "      <td>6.779922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.040536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.877035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.931826</td>\n",
       "      <td>4.242482</td>\n",
       "      <td>9.161518</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.929589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.124683</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.994850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.273093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.183117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>4.372593</td>\n",
       "      <td>9.356884</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>6.640529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.672033</td>\n",
       "      <td>7.190111</td>\n",
       "      <td>7.243870</td>\n",
       "      <td>6.523562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.455298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.373746</td>\n",
       "      <td>5.141664</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.252273</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>10.858518</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>7.163172</td>\n",
       "      <td>8.296796</td>\n",
       "      <td>7.331060</td>\n",
       "      <td>7.669028</td>\n",
       "      <td>8.536211</td>\n",
       "      <td>8.536211</td>\n",
       "      <td>7.529943</td>\n",
       "      <td>6.970730</td>\n",
       "      <td>8.536211</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.305860</td>\n",
       "      <td>7.261927</td>\n",
       "      <td>6.347389</td>\n",
       "      <td>6.920672</td>\n",
       "      <td>5.888878</td>\n",
       "      <td>6.357842</td>\n",
       "      <td>6.685861</td>\n",
       "      <td>9.741027</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage      LotArea  OverallQual  OverallCond  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean      3.806538     4.200201     9.085644     6.174927     1.871282   \n",
       "std       0.689389     0.322355     0.488516     1.397616     0.157738   \n",
       "min       3.044522     3.091042     7.303170     2.000000     0.693147   \n",
       "25%       3.044522     4.110874     8.915801     5.000000     1.791759   \n",
       "50%       3.931826     4.242482     9.161518     6.000000     1.791759   \n",
       "75%       4.262680     4.372593     9.356884     7.000000     1.945910   \n",
       "max       5.252273     5.303305    10.858518    10.000000     2.302585   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1372.000000   1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean   1973.043003   1984.373178     2.131305     4.361030     0.739250   \n",
       "std      29.505436     20.789679     2.637444     2.922026     1.949698   \n",
       "min    1879.000000   1950.000000     0.000000     0.000000     0.000000   \n",
       "25%    1955.000000   1965.000000     0.000000     0.000000     0.000000   \n",
       "50%    1976.000000   1993.000000     0.000000     5.929589     0.000000   \n",
       "75%    2002.000000   2004.000000     5.164786     6.640529     0.000000   \n",
       "max    2010.000000   2010.000000     7.163172     8.296796     7.331060   \n",
       "\n",
       "         BsmtUnfSF  TotalBsmtSF     1stFlrSF     2ndFlrSF  LowQualFinSF  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000   1372.000000   \n",
       "mean      5.633517     6.769547     7.009270     2.799118      0.049945   \n",
       "std       1.824946     1.082098     0.324701     3.266460      0.536193   \n",
       "min       0.000000     0.000000     6.011267     0.000000      0.000000   \n",
       "25%       5.401549     6.689909     6.779922     0.000000      0.000000   \n",
       "50%       6.124683     6.907755     6.994850     0.000000      0.000000   \n",
       "75%       6.672033     7.190111     7.243870     6.523562      0.000000   \n",
       "max       7.669028     8.536211     8.536211     7.529943      6.970730   \n",
       "\n",
       "         GrLivArea  BsmtFullBath  BsmtHalfBath     FullBath     HalfBath  \\\n",
       "count  1372.000000   1372.000000   1372.000000  1372.000000  1372.000000   \n",
       "mean      7.264022      0.444606      0.044754     1.582362     0.385569   \n",
       "std       0.310957      0.525631      0.171360     0.553283     0.506006   \n",
       "min       6.011267      0.000000      0.000000     0.000000     0.000000   \n",
       "25%       7.040536      0.000000      0.000000     1.000000     0.000000   \n",
       "50%       7.273093      0.000000      0.000000     2.000000     0.000000   \n",
       "75%       7.455298      1.000000      0.000000     2.000000     1.000000   \n",
       "max       8.536211      2.000000      1.098612     4.000000     2.000000   \n",
       "\n",
       "       BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd   Fireplaces   GarageCars  \\\n",
       "count   1372.000000   1372.000000   1372.000000  1372.000000  1372.000000   \n",
       "mean       2.841108      0.705941      1.981069     0.397003     1.867347   \n",
       "std        0.802695      0.074718      0.194997     0.394243     0.673483   \n",
       "min        0.000000      0.000000      1.386294     0.000000     1.000000   \n",
       "25%        2.000000      0.693147      1.791759     0.000000     1.000000   \n",
       "50%        3.000000      0.693147      1.945910     0.693147     2.000000   \n",
       "75%        3.000000      0.693147      2.079442     0.693147     2.000000   \n",
       "max        6.000000      1.098612      2.772589     1.609438     5.000000   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1372.000000  1372.000000  1372.000000    1372.000000  1372.000000   \n",
       "mean      6.143472     2.530973     2.405970       0.774055     0.045891   \n",
       "std       0.387257     2.598820     2.151033       1.773732     0.490089   \n",
       "min       4.615121     0.000000     0.000000       0.000000     0.000000   \n",
       "25%       5.877035     0.000000     0.000000       0.000000     0.000000   \n",
       "50%       6.183117     0.000000     3.433987       0.000000     0.000000   \n",
       "75%       6.373746     5.141664     4.304065       0.000000     0.000000   \n",
       "max       7.305860     7.261927     6.347389       6.920672     5.888878   \n",
       "\n",
       "       ScreenPorch     PoolArea      MiscVal       MoSold       YrSold  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean      0.515526     0.025828     0.221003     6.129009  2007.765306   \n",
       "std       1.546026     0.391644     1.215288     2.711534     1.298158   \n",
       "min       0.000000     0.000000     0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000     0.000000     4.000000  2007.000000   \n",
       "50%       0.000000     0.000000     0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000     0.000000     8.000000  2009.000000   \n",
       "max       6.357842     6.685861     9.741027    12.000000  2010.000000   \n",
       "\n",
       "       MSZoning_C (all)  MSZoning_FV  MSZoning_RH  MSZoning_RL  MSZoning_RM  \\\n",
       "count       1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean           0.005102     0.053936     0.006560     0.779883     0.154519   \n",
       "std            0.071272     0.225973     0.080756     0.414476     0.361577   \n",
       "min            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%            0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "50%            0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%            0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max            1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       Street_Grvl  Street_Pave   Alley_Grvl   Alley_None   Alley_Pave  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean      0.002915     0.997085     0.042274     0.931487     0.026239   \n",
       "std       0.053936     0.053936     0.201287     0.252716     0.159904   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       LotShape_IR1  LotShape_IR2  LotShape_IR3  LotShape_Reg  \\\n",
       "count   1372.000000   1372.000000   1372.000000   1372.000000   \n",
       "mean       0.345481      0.025510      0.003644      0.625364   \n",
       "std        0.475698      0.157726      0.060280      0.484205   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000   \n",
       "75%        1.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       LandContour_Bnk  LandContour_HLS  LandContour_Low  LandContour_Lvl  \\\n",
       "count      1372.000000      1372.000000      1372.000000      1372.000000   \n",
       "mean          0.036443         0.050292         0.015306         0.897959   \n",
       "std           0.187458         0.218626         0.122812         0.302812   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           0.000000         0.000000         0.000000         1.000000   \n",
       "50%           0.000000         0.000000         0.000000         1.000000   \n",
       "75%           0.000000         0.000000         0.000000         1.000000   \n",
       "max           1.000000         1.000000         1.000000         1.000000   \n",
       "\n",
       "       Utilities_AllPub  LotConfig_Corner  LotConfig_CulDSac  LotConfig_FR2  \\\n",
       "count            1372.0       1372.000000        1372.000000    1372.000000   \n",
       "mean                1.0          0.172012           0.059038       0.026239   \n",
       "std                 0.0          0.377528           0.235782       0.159904   \n",
       "min                 1.0          0.000000           0.000000       0.000000   \n",
       "25%                 1.0          0.000000           0.000000       0.000000   \n",
       "50%                 1.0          0.000000           0.000000       0.000000   \n",
       "75%                 1.0          0.000000           0.000000       0.000000   \n",
       "max                 1.0          1.000000           1.000000       1.000000   \n",
       "\n",
       "       LotConfig_FR3  LotConfig_Inside  LandSlope_Gtl  LandSlope_Mod  \\\n",
       "count    1372.000000       1372.000000    1372.000000    1372.000000   \n",
       "mean        0.006560          0.736152       0.954810       0.043003   \n",
       "std         0.080756          0.440879       0.207795       0.202938   \n",
       "min         0.000000          0.000000       0.000000       0.000000   \n",
       "25%         0.000000          0.000000       1.000000       0.000000   \n",
       "50%         0.000000          1.000000       1.000000       0.000000   \n",
       "75%         0.000000          1.000000       1.000000       0.000000   \n",
       "max         1.000000          1.000000       1.000000       1.000000   \n",
       "\n",
       "       LandSlope_Sev  Neighborhood_Blmngtn  Neighborhood_Blueste  \\\n",
       "count    1372.000000           1372.000000           1372.000000   \n",
       "mean        0.002187              0.008017              0.005831   \n",
       "std         0.046727              0.089213              0.076165   \n",
       "min         0.000000              0.000000              0.000000   \n",
       "25%         0.000000              0.000000              0.000000   \n",
       "50%         0.000000              0.000000              0.000000   \n",
       "75%         0.000000              0.000000              0.000000   \n",
       "max         1.000000              1.000000              1.000000   \n",
       "\n",
       "       Neighborhood_BrDale  Neighborhood_BrkSide  Neighborhood_ClearCr  \\\n",
       "count          1372.000000           1372.000000           1372.000000   \n",
       "mean              0.010204              0.034257              0.010933   \n",
       "std               0.100535              0.181954              0.104025   \n",
       "min               0.000000              0.000000              0.000000   \n",
       "25%               0.000000              0.000000              0.000000   \n",
       "50%               0.000000              0.000000              0.000000   \n",
       "75%               0.000000              0.000000              0.000000   \n",
       "max               1.000000              1.000000              1.000000   \n",
       "\n",
       "       Neighborhood_CollgCr  Neighborhood_Crawfor  Neighborhood_Edwards  \\\n",
       "count           1372.000000           1372.000000           1372.000000   \n",
       "mean               0.085277              0.037901              0.056851   \n",
       "std                0.279395              0.191026              0.231643   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max                1.000000              1.000000              1.000000   \n",
       "\n",
       "       Neighborhood_Gilbert  Neighborhood_IDOTRR  Neighborhood_MeadowV  \\\n",
       "count           1372.000000          1372.000000           1372.000000   \n",
       "mean               0.061953             0.029155              0.009475   \n",
       "std                0.241159             0.168301              0.096914   \n",
       "min                0.000000             0.000000              0.000000   \n",
       "25%                0.000000             0.000000              0.000000   \n",
       "50%                0.000000             0.000000              0.000000   \n",
       "75%                0.000000             0.000000              0.000000   \n",
       "max                1.000000             1.000000              1.000000   \n",
       "\n",
       "       Neighborhood_Mitchel  Neighborhood_NAmes  Neighborhood_NPkVill  \\\n",
       "count           1372.000000         1372.000000           1372.000000   \n",
       "mean               0.044461            0.155977              0.010204   \n",
       "std                0.206191            0.362966              0.100535   \n",
       "min                0.000000            0.000000              0.000000   \n",
       "25%                0.000000            0.000000              0.000000   \n",
       "50%                0.000000            0.000000              0.000000   \n",
       "75%                0.000000            0.000000              0.000000   \n",
       "max                1.000000            1.000000              1.000000   \n",
       "\n",
       "       Neighborhood_NWAmes  Neighborhood_NoRidge  Neighborhood_NridgHt  \\\n",
       "count          1372.000000           1372.000000           1372.000000   \n",
       "mean              0.042274              0.021866              0.064869   \n",
       "std               0.201287              0.146299              0.246384   \n",
       "min               0.000000              0.000000              0.000000   \n",
       "25%               0.000000              0.000000              0.000000   \n",
       "50%               0.000000              0.000000              0.000000   \n",
       "75%               0.000000              0.000000              0.000000   \n",
       "max               1.000000              1.000000              1.000000   \n",
       "\n",
       "       Neighborhood_OldTown  Neighborhood_SWISU  Neighborhood_Sawyer  \\\n",
       "count           1372.000000         1372.000000          1372.000000   \n",
       "mean               0.077988            0.013120             0.053207   \n",
       "std                0.268251            0.113828             0.224528   \n",
       "min                0.000000            0.000000             0.000000   \n",
       "25%                0.000000            0.000000             0.000000   \n",
       "50%                0.000000            0.000000             0.000000   \n",
       "75%                0.000000            0.000000             0.000000   \n",
       "max                1.000000            1.000000             1.000000   \n",
       "\n",
       "       Neighborhood_SawyerW  Neighborhood_Somerst  Neighborhood_StoneBr  \\\n",
       "count           1372.000000           1372.000000            1372.00000   \n",
       "mean               0.043003              0.069971               0.01895   \n",
       "std                0.202938              0.255191               0.13640   \n",
       "min                0.000000              0.000000               0.00000   \n",
       "25%                0.000000              0.000000               0.00000   \n",
       "50%                0.000000              0.000000               0.00000   \n",
       "75%                0.000000              0.000000               0.00000   \n",
       "max                1.000000              1.000000               1.00000   \n",
       "\n",
       "       Neighborhood_Timber  Neighborhood_Veenker  Condition1_Artery  \\\n",
       "count          1372.000000           1372.000000        1372.000000   \n",
       "mean              0.024781              0.009475           0.026239   \n",
       "std               0.155515              0.096914           0.159904   \n",
       "min               0.000000              0.000000           0.000000   \n",
       "25%               0.000000              0.000000           0.000000   \n",
       "50%               0.000000              0.000000           0.000000   \n",
       "75%               0.000000              0.000000           0.000000   \n",
       "max               1.000000              1.000000           1.000000   \n",
       "\n",
       "       Condition1_Feedr  Condition1_Norm  Condition1_PosA  Condition1_PosN  \\\n",
       "count       1372.000000      1372.000000      1372.000000      1372.000000   \n",
       "mean           0.053936         0.862974         0.008746         0.014577   \n",
       "std            0.225973         0.344000         0.093146         0.119897   \n",
       "min            0.000000         0.000000         0.000000         0.000000   \n",
       "25%            0.000000         1.000000         0.000000         0.000000   \n",
       "50%            0.000000         1.000000         0.000000         0.000000   \n",
       "75%            0.000000         1.000000         0.000000         0.000000   \n",
       "max            1.000000         1.000000         1.000000         1.000000   \n",
       "\n",
       "       Condition1_RRAe  Condition1_RRAn  Condition1_RRNe  Condition1_RRNn  \\\n",
       "count      1372.000000      1372.000000      1372.000000      1372.000000   \n",
       "mean          0.010204         0.017493         0.002915         0.002915   \n",
       "std           0.100535         0.131146         0.053936         0.053936   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           0.000000         0.000000         0.000000         0.000000   \n",
       "50%           0.000000         0.000000         0.000000         0.000000   \n",
       "75%           0.000000         0.000000         0.000000         0.000000   \n",
       "max           1.000000         1.000000         1.000000         1.000000   \n",
       "\n",
       "       Condition2_Artery  Condition2_Feedr  Condition2_Norm  Condition2_PosA  \\\n",
       "count        1372.000000       1372.000000      1372.000000      1372.000000   \n",
       "mean            0.001458          0.005102         0.989796         0.002187   \n",
       "std             0.038166          0.071272         0.100535         0.046727   \n",
       "min             0.000000          0.000000         0.000000         0.000000   \n",
       "25%             0.000000          0.000000         1.000000         0.000000   \n",
       "50%             0.000000          0.000000         1.000000         0.000000   \n",
       "75%             0.000000          0.000000         1.000000         0.000000   \n",
       "max             1.000000          1.000000         1.000000         1.000000   \n",
       "\n",
       "       Condition2_PosN  BldgType_1Fam  BldgType_2fmCon  BldgType_Duplex  \\\n",
       "count      1372.000000    1372.000000      1372.000000      1372.000000   \n",
       "mean          0.001458       0.839650         0.014577         0.029883   \n",
       "std           0.038166       0.367064         0.119897         0.170328   \n",
       "min           0.000000       0.000000         0.000000         0.000000   \n",
       "25%           0.000000       1.000000         0.000000         0.000000   \n",
       "50%           0.000000       1.000000         0.000000         0.000000   \n",
       "75%           0.000000       1.000000         0.000000         0.000000   \n",
       "max           1.000000       1.000000         1.000000         1.000000   \n",
       "\n",
       "       BldgType_Twnhs  BldgType_TwnhsE  HouseStyle_1.5Fin  HouseStyle_1.5Unf  \\\n",
       "count     1372.000000      1372.000000        1372.000000        1372.000000   \n",
       "mean         0.034985         0.080904           0.105685           0.002915   \n",
       "std          0.183810         0.272787           0.307546           0.053936   \n",
       "min          0.000000         0.000000           0.000000           0.000000   \n",
       "25%          0.000000         0.000000           0.000000           0.000000   \n",
       "50%          0.000000         0.000000           0.000000           0.000000   \n",
       "75%          0.000000         0.000000           0.000000           0.000000   \n",
       "max          1.000000         1.000000           1.000000           1.000000   \n",
       "\n",
       "       HouseStyle_1Story  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
       "count         1372.00000        1372.000000        1372.000000   \n",
       "mean             0.51312           0.007289           0.296647   \n",
       "std              0.50001           0.085093           0.456946   \n",
       "min              0.00000           0.000000           0.000000   \n",
       "25%              0.00000           0.000000           0.000000   \n",
       "50%              1.00000           0.000000           0.000000   \n",
       "75%              1.00000           0.000000           1.000000   \n",
       "max              1.00000           1.000000           1.000000   \n",
       "\n",
       "       HouseStyle_SFoyer  HouseStyle_SLvl  RoofStyle_Flat  RoofStyle_Gable  \\\n",
       "count        1372.000000      1372.000000     1372.000000      1372.000000   \n",
       "mean            0.028426         0.045918        0.002915         0.800292   \n",
       "std             0.166246         0.209384        0.053936         0.399927   \n",
       "min             0.000000         0.000000        0.000000         0.000000   \n",
       "25%             0.000000         0.000000        0.000000         1.000000   \n",
       "50%             0.000000         0.000000        0.000000         1.000000   \n",
       "75%             0.000000         0.000000        0.000000         1.000000   \n",
       "max             1.000000         1.000000        1.000000         1.000000   \n",
       "\n",
       "       RoofStyle_Gambrel  RoofStyle_Hip  RoofStyle_Mansard  RoofStyle_Shed  \\\n",
       "count        1372.000000    1372.000000        1372.000000     1372.000000   \n",
       "mean            0.007289       0.185131           0.002187        0.002187   \n",
       "std             0.085093       0.388546           0.046727        0.046727   \n",
       "min             0.000000       0.000000           0.000000        0.000000   \n",
       "25%             0.000000       0.000000           0.000000        0.000000   \n",
       "50%             0.000000       0.000000           0.000000        0.000000   \n",
       "75%             0.000000       0.000000           0.000000        0.000000   \n",
       "max             1.000000       1.000000           1.000000        1.000000   \n",
       "\n",
       "       RoofMatl_CompShg  RoofMatl_Tar&Grv  RoofMatl_WdShake  RoofMatl_WdShngl  \\\n",
       "count       1372.000000       1372.000000       1372.000000       1372.000000   \n",
       "mean           0.990525          0.005831          0.002915          0.000729   \n",
       "std            0.096914          0.076165          0.053936          0.026997   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            1.000000          0.000000          0.000000          0.000000   \n",
       "50%            1.000000          0.000000          0.000000          0.000000   \n",
       "75%            1.000000          0.000000          0.000000          0.000000   \n",
       "max            1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       Exterior1st_AsbShng  Exterior1st_BrkComm  Exterior1st_BrkFace  \\\n",
       "count          1372.000000          1372.000000          1372.000000   \n",
       "mean              0.013848             0.002915             0.024781   \n",
       "std               0.116904             0.053936             0.155515   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               0.000000             0.000000             0.000000   \n",
       "75%               0.000000             0.000000             0.000000   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       Exterior1st_CemntBd  Exterior1st_HdBoard  Exterior1st_MetalSd  \\\n",
       "count          1372.000000          1372.000000          1372.000000   \n",
       "mean              0.042274             0.157434             0.158892   \n",
       "std               0.201287             0.364343             0.365709   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               0.000000             0.000000             0.000000   \n",
       "75%               0.000000             0.000000             0.000000   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       Exterior1st_Plywood  Exterior1st_Stucco  Exterior1st_VinylSd  \\\n",
       "count          1372.000000         1372.000000          1372.000000   \n",
       "mean              0.077259            0.010933             0.360787   \n",
       "std               0.267100            0.104025             0.480404   \n",
       "min               0.000000            0.000000             0.000000   \n",
       "25%               0.000000            0.000000             0.000000   \n",
       "50%               0.000000            0.000000             0.000000   \n",
       "75%               0.000000            0.000000             1.000000   \n",
       "max               1.000000            1.000000             1.000000   \n",
       "\n",
       "       Exterior1st_Wd Sdng  Exterior1st_WdShing  Exterior2nd_AsbShng  \\\n",
       "count          1372.000000           1372.00000          1372.000000   \n",
       "mean              0.131924              0.01895             0.011662   \n",
       "std               0.338532              0.13640             0.107397   \n",
       "min               0.000000              0.00000             0.000000   \n",
       "25%               0.000000              0.00000             0.000000   \n",
       "50%               0.000000              0.00000             0.000000   \n",
       "75%               0.000000              0.00000             0.000000   \n",
       "max               1.000000              1.00000             1.000000   \n",
       "\n",
       "       Exterior2nd_Brk Cmn  Exterior2nd_BrkFace  Exterior2nd_CmentBd  \\\n",
       "count          1372.000000          1372.000000          1372.000000   \n",
       "mean              0.010933             0.014577             0.043003   \n",
       "std               0.104025             0.119897             0.202938   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               0.000000             0.000000             0.000000   \n",
       "75%               0.000000             0.000000             0.000000   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       Exterior2nd_HdBoard  Exterior2nd_ImStucc  Exterior2nd_MetalSd  \\\n",
       "count          1372.000000          1372.000000          1372.000000   \n",
       "mean              0.140671             0.003644             0.161808   \n",
       "std               0.347808             0.060280             0.368408   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               0.000000             0.000000             0.000000   \n",
       "75%               0.000000             0.000000             0.000000   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       Exterior2nd_Plywood  Exterior2nd_Stone  Exterior2nd_Stucco  \\\n",
       "count          1372.000000        1372.000000         1372.000000   \n",
       "mean              0.086735           0.000729            0.012391   \n",
       "std               0.281549           0.026997            0.110662   \n",
       "min               0.000000           0.000000            0.000000   \n",
       "25%               0.000000           0.000000            0.000000   \n",
       "50%               0.000000           0.000000            0.000000   \n",
       "75%               0.000000           0.000000            0.000000   \n",
       "max               1.000000           1.000000            1.000000   \n",
       "\n",
       "       Exterior2nd_VinylSd  Exterior2nd_Wd Sdng  Exterior2nd_Wd Shng  \\\n",
       "count          1372.000000          1372.000000          1372.000000   \n",
       "mean              0.359329             0.128280             0.026239   \n",
       "std               0.479979             0.334523             0.159904   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               0.000000             0.000000             0.000000   \n",
       "75%               1.000000             0.000000             0.000000   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       MasVnrType_BrkCmn  MasVnrType_BrkFace  MasVnrType_None  \\\n",
       "count        1372.000000         1372.000000      1372.000000   \n",
       "mean            0.005831            0.311224         0.595481   \n",
       "std             0.076165            0.463163         0.490978   \n",
       "min             0.000000            0.000000         0.000000   \n",
       "25%             0.000000            0.000000         0.000000   \n",
       "50%             0.000000            0.000000         1.000000   \n",
       "75%             0.000000            1.000000         1.000000   \n",
       "max             1.000000            1.000000         1.000000   \n",
       "\n",
       "       MasVnrType_Stone  ExterQual_Ex  ExterQual_Fa  ExterQual_Gd  \\\n",
       "count       1372.000000   1372.000000   1372.000000   1372.000000   \n",
       "mean           0.087464      0.040087      0.008017      0.352770   \n",
       "std            0.282616      0.196236      0.089213      0.478006   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%            0.000000      0.000000      0.000000      0.000000   \n",
       "50%            0.000000      0.000000      0.000000      0.000000   \n",
       "75%            0.000000      0.000000      0.000000      1.000000   \n",
       "max            1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ExterQual_TA  ExterCond_Ex  ExterCond_Fa  ExterCond_Gd  ExterCond_Po  \\\n",
       "count   1372.000000   1372.000000   1372.000000   1372.000000   1372.000000   \n",
       "mean       0.599125      0.006560      0.019679      0.104956      0.000729   \n",
       "std        0.490254      0.080756      0.138946      0.306609      0.026997   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ExterCond_TA  Foundation_BrkTil  Foundation_CBlock  Foundation_PConc  \\\n",
       "count   1372.000000        1372.000000        1372.000000       1372.000000   \n",
       "mean       0.868076           0.107143           0.412536          0.462828   \n",
       "std        0.338532           0.309408           0.492470          0.498798   \n",
       "min        0.000000           0.000000           0.000000          0.000000   \n",
       "25%        1.000000           0.000000           0.000000          0.000000   \n",
       "50%        1.000000           0.000000           0.000000          0.000000   \n",
       "75%        1.000000           0.000000           1.000000          1.000000   \n",
       "max        1.000000           1.000000           1.000000          1.000000   \n",
       "\n",
       "       Foundation_Slab  Foundation_Stone  Foundation_Wood  BsmtQual_Ex  \\\n",
       "count      1372.000000       1372.000000      1372.000000  1372.000000   \n",
       "mean          0.013120          0.002915         0.001458     0.099854   \n",
       "std           0.113828          0.053936         0.038166     0.299915   \n",
       "min           0.000000          0.000000         0.000000     0.000000   \n",
       "25%           0.000000          0.000000         0.000000     0.000000   \n",
       "50%           0.000000          0.000000         0.000000     0.000000   \n",
       "75%           0.000000          0.000000         0.000000     0.000000   \n",
       "max           1.000000          1.000000         1.000000     1.000000   \n",
       "\n",
       "       BsmtQual_Fa  BsmtQual_Gd  BsmtQual_No  BsmtQual_TA  BsmtCond_Fa  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean      0.030612     0.416910     0.023324     0.429300     0.034985   \n",
       "std       0.172328     0.493227     0.150984     0.495157     0.183810   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       BsmtCond_Gd  BsmtCond_No  BsmtCond_Po  BsmtCond_TA  BsmtExposure_Av  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000      1372.000000   \n",
       "mean      0.039359     0.024052     0.000729     0.900875         0.136297   \n",
       "std       0.194518     0.153268     0.026997     0.298939         0.343229   \n",
       "min       0.000000     0.000000     0.000000     0.000000         0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000         0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000         0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000         0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000         1.000000   \n",
       "\n",
       "       BsmtExposure_Gd  BsmtExposure_Mn  BsmtExposure_No  BsmtFinType1_ALQ  \\\n",
       "count      1372.000000      1372.000000      1372.000000       1372.000000   \n",
       "mean          0.101312         0.086735         0.675656          0.147230   \n",
       "std           0.301851         0.281549         0.468300          0.354465   \n",
       "min           0.000000         0.000000         0.000000          0.000000   \n",
       "25%           0.000000         0.000000         0.000000          0.000000   \n",
       "50%           0.000000         0.000000         1.000000          0.000000   \n",
       "75%           0.000000         0.000000         1.000000          0.000000   \n",
       "max           1.000000         1.000000         1.000000          1.000000   \n",
       "\n",
       "       BsmtFinType1_BLQ  BsmtFinType1_GLQ  BsmtFinType1_LwQ  BsmtFinType1_No  \\\n",
       "count       1372.000000       1372.000000       1372.000000      1372.000000   \n",
       "mean           0.086006          0.306122          0.056851         0.021866   \n",
       "std            0.280475          0.461049          0.231643         0.146299   \n",
       "min            0.000000          0.000000          0.000000         0.000000   \n",
       "25%            0.000000          0.000000          0.000000         0.000000   \n",
       "50%            0.000000          0.000000          0.000000         0.000000   \n",
       "75%            0.000000          1.000000          0.000000         0.000000   \n",
       "max            1.000000          1.000000          1.000000         1.000000   \n",
       "\n",
       "       BsmtFinType1_Rec  BsmtFinType1_Unf  BsmtFinType2_ALQ  BsmtFinType2_BLQ  \\\n",
       "count       1372.000000       1372.000000       1372.000000       1372.000000   \n",
       "mean           0.108601          0.273324          0.023324          0.024781   \n",
       "std            0.311251          0.445828          0.150984          0.155515   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.000000          0.000000          0.000000          0.000000   \n",
       "75%            0.000000          1.000000          0.000000          0.000000   \n",
       "max            1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       BsmtFinType2_GLQ  BsmtFinType2_LwQ  BsmtFinType2_No  BsmtFinType2_Rec  \\\n",
       "count       1372.000000       1372.000000      1372.000000       1372.000000   \n",
       "mean           0.014577          0.029883         0.021866          0.036443   \n",
       "std            0.119897          0.170328         0.146299          0.187458   \n",
       "min            0.000000          0.000000         0.000000          0.000000   \n",
       "25%            0.000000          0.000000         0.000000          0.000000   \n",
       "50%            0.000000          0.000000         0.000000          0.000000   \n",
       "75%            0.000000          0.000000         0.000000          0.000000   \n",
       "max            1.000000          1.000000         1.000000          1.000000   \n",
       "\n",
       "       BsmtFinType2_Unf  Heating_GasA  Heating_GasW  Heating_Wall  \\\n",
       "count       1372.000000   1372.000000   1372.000000   1372.000000   \n",
       "mean           0.849125      0.993440      0.005831      0.000729   \n",
       "std            0.358057      0.080756      0.076165      0.026997   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%            1.000000      1.000000      0.000000      0.000000   \n",
       "50%            1.000000      1.000000      0.000000      0.000000   \n",
       "75%            1.000000      1.000000      0.000000      0.000000   \n",
       "max            1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       HeatingQC_Ex  HeatingQC_Fa  HeatingQC_Gd  HeatingQC_Po  HeatingQC_TA  \\\n",
       "count   1372.000000   1372.000000   1372.000000   1372.000000   1372.000000   \n",
       "mean       0.529155      0.025510      0.159621      0.000729      0.284985   \n",
       "std        0.499331      0.157726      0.366388      0.026997      0.451572   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       CentralAir_N  CentralAir_Y  Electrical_FuseA  Electrical_FuseF  \\\n",
       "count   1372.000000   1372.000000       1372.000000       1372.000000   \n",
       "mean       0.048105      0.951895          0.059038          0.013120   \n",
       "std        0.214066      0.214066          0.235782          0.113828   \n",
       "min        0.000000      0.000000          0.000000          0.000000   \n",
       "25%        0.000000      1.000000          0.000000          0.000000   \n",
       "50%        0.000000      1.000000          0.000000          0.000000   \n",
       "75%        0.000000      1.000000          0.000000          0.000000   \n",
       "max        1.000000      1.000000          1.000000          1.000000   \n",
       "\n",
       "       Electrical_FuseP  Electrical_SBrkr  KitchenQual_Ex  KitchenQual_Fa  \\\n",
       "count       1372.000000       1372.000000     1372.000000     1372.000000   \n",
       "mean           0.002187          0.925656        0.075073        0.016764   \n",
       "std            0.046727          0.262426        0.263605        0.128432   \n",
       "min            0.000000          0.000000        0.000000        0.000000   \n",
       "25%            0.000000          1.000000        0.000000        0.000000   \n",
       "50%            0.000000          1.000000        0.000000        0.000000   \n",
       "75%            0.000000          1.000000        0.000000        0.000000   \n",
       "max            1.000000          1.000000        1.000000        1.000000   \n",
       "\n",
       "       KitchenQual_Gd  KitchenQual_TA  Functional_Maj1  Functional_Maj2  \\\n",
       "count     1372.000000     1372.000000      1372.000000      1372.000000   \n",
       "mean         0.399417        0.508746         0.002915         0.002187   \n",
       "std          0.489957        0.500106         0.053936         0.046727   \n",
       "min          0.000000        0.000000         0.000000         0.000000   \n",
       "25%          0.000000        0.000000         0.000000         0.000000   \n",
       "50%          0.000000        1.000000         0.000000         0.000000   \n",
       "75%          1.000000        1.000000         0.000000         0.000000   \n",
       "max          1.000000        1.000000         1.000000         1.000000   \n",
       "\n",
       "       Functional_Min1  Functional_Min2  Functional_Mod  Functional_Typ  \\\n",
       "count      1372.000000      1372.000000     1372.000000     1372.000000   \n",
       "mean          0.022595         0.021866        0.012391        0.938047   \n",
       "std           0.148662         0.146299        0.110662        0.241159   \n",
       "min           0.000000         0.000000        0.000000        0.000000   \n",
       "25%           0.000000         0.000000        0.000000        1.000000   \n",
       "50%           0.000000         0.000000        0.000000        1.000000   \n",
       "75%           0.000000         0.000000        0.000000        1.000000   \n",
       "max           1.000000         1.000000        1.000000        1.000000   \n",
       "\n",
       "       FireplaceQu_Ex  FireplaceQu_Fa  FireplaceQu_Gd  FireplaceQu_No  \\\n",
       "count     1372.000000     1372.000000     1372.000000     1372.000000   \n",
       "mean         0.013848        0.029883        0.259475        0.475219   \n",
       "std          0.116904        0.170328        0.438507        0.499568   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          0.000000        0.000000        0.000000        0.000000   \n",
       "75%          0.000000        0.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       FireplaceQu_Po  FireplaceQu_TA  GarageType_2Types  GarageType_Attchd  \\\n",
       "count      1372.00000     1372.000000        1372.000000        1372.000000   \n",
       "mean          0.01895        0.202624           0.012391           0.618076   \n",
       "std           0.13640        0.402101           0.110662           0.486035   \n",
       "min           0.00000        0.000000           0.000000           0.000000   \n",
       "25%           0.00000        0.000000           0.000000           0.000000   \n",
       "50%           0.00000        0.000000           0.000000           1.000000   \n",
       "75%           0.00000        0.000000           0.000000           1.000000   \n",
       "max           1.00000        1.000000           1.000000           1.000000   \n",
       "\n",
       "       GarageType_Basment  GarageType_BuiltIn  GarageType_CarPort  \\\n",
       "count         1372.000000         1372.000000         1372.000000   \n",
       "mean             0.012391            0.071429            0.004373   \n",
       "std              0.110662            0.257633            0.066009   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       GarageType_Detchd  GarageFinish_Fin  GarageFinish_RFn  \\\n",
       "count        1372.000000       1372.000000       1372.000000   \n",
       "mean            0.281341          0.267493          0.283528   \n",
       "std             0.449817          0.442813          0.450875   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             0.000000          0.000000          0.000000   \n",
       "75%             1.000000          1.000000          1.000000   \n",
       "max             1.000000          1.000000          1.000000   \n",
       "\n",
       "       GarageFinish_Unf  GarageQual_Fa  GarageQual_Gd  GarageQual_Po  \\\n",
       "count       1372.000000    1372.000000    1372.000000    1372.000000   \n",
       "mean           0.448980       0.053207       0.007289       0.001458   \n",
       "std            0.497571       0.224528       0.085093       0.038166   \n",
       "min            0.000000       0.000000       0.000000       0.000000   \n",
       "25%            0.000000       0.000000       0.000000       0.000000   \n",
       "50%            0.000000       0.000000       0.000000       0.000000   \n",
       "75%            1.000000       0.000000       0.000000       0.000000   \n",
       "max            1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       GarageQual_TA  GarageCond_Ex  GarageCond_Fa  GarageCond_Gd  \\\n",
       "count    1372.000000    1372.000000    1372.000000    1372.000000   \n",
       "mean        0.938047       0.000729       0.026968       0.004373   \n",
       "std         0.241159       0.026997       0.162049       0.066009   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       GarageCond_Po  GarageCond_TA  PavedDrive_N  PavedDrive_P  PavedDrive_Y  \\\n",
       "count    1372.000000    1372.000000   1372.000000   1372.000000   1372.000000   \n",
       "mean        0.004373       0.963557      0.059038      0.022595      0.918367   \n",
       "std         0.066009       0.187458      0.235782      0.148662      0.273904   \n",
       "min         0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000       1.000000      0.000000      0.000000      1.000000   \n",
       "50%         0.000000       1.000000      0.000000      0.000000      1.000000   \n",
       "75%         0.000000       1.000000      0.000000      0.000000      1.000000   \n",
       "max         1.000000       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         PoolQC_Ex    PoolQC_Gd    PoolQC_No  Fence_GdPrv   Fence_GdWo  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean      0.001458     0.000729     0.997813     0.042274     0.039359   \n",
       "std       0.038166     0.026997     0.046727     0.201287     0.194518   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       Fence_MnPrv   Fence_MnWw     Fence_No  MiscFeature_Gar2  \\\n",
       "count  1372.000000  1372.000000  1372.000000       1372.000000   \n",
       "mean      0.118805     0.000729     0.798834          0.002187   \n",
       "std       0.323677     0.026997     0.401018          0.046727   \n",
       "min       0.000000     0.000000     0.000000          0.000000   \n",
       "25%       0.000000     0.000000     1.000000          0.000000   \n",
       "50%       0.000000     0.000000     1.000000          0.000000   \n",
       "75%       0.000000     0.000000     1.000000          0.000000   \n",
       "max       1.000000     1.000000     1.000000          1.000000   \n",
       "\n",
       "       MiscFeature_No  MiscFeature_Othr  MiscFeature_Shed  SaleType_COD  \\\n",
       "count     1372.000000       1372.000000       1372.000000   1372.000000   \n",
       "mean         0.967201          0.001458          0.029155      0.029883   \n",
       "std          0.178175          0.038166          0.168301      0.170328   \n",
       "min          0.000000          0.000000          0.000000      0.000000   \n",
       "25%          1.000000          0.000000          0.000000      0.000000   \n",
       "50%          1.000000          0.000000          0.000000      0.000000   \n",
       "75%          1.000000          0.000000          0.000000      0.000000   \n",
       "max          1.000000          1.000000          1.000000      1.000000   \n",
       "\n",
       "       SaleType_CWD  SaleType_Con  SaleType_ConLD  SaleType_ConLI  \\\n",
       "count   1372.000000   1372.000000     1372.000000     1372.000000   \n",
       "mean       0.005831      0.002187        0.009475        0.002915   \n",
       "std        0.076165      0.046727        0.096914        0.053936   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        0.000000      0.000000        0.000000        0.000000   \n",
       "50%        0.000000      0.000000        0.000000        0.000000   \n",
       "75%        0.000000      0.000000        0.000000        0.000000   \n",
       "max        1.000000      1.000000        1.000000        1.000000   \n",
       "\n",
       "       SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "count     1372.000000   1372.000000   1372.000000  1372.000000   \n",
       "mean         0.002187      0.083819      0.002187     0.861516   \n",
       "std          0.046727      0.277218      0.046727     0.345533   \n",
       "min          0.000000      0.000000      0.000000     0.000000   \n",
       "25%          0.000000      0.000000      0.000000     1.000000   \n",
       "50%          0.000000      0.000000      0.000000     1.000000   \n",
       "75%          0.000000      0.000000      0.000000     1.000000   \n",
       "max          1.000000      1.000000      1.000000     1.000000   \n",
       "\n",
       "       SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "count            1372.000000            1372.000000           1372.000000   \n",
       "mean                0.053207               0.003644              0.007289   \n",
       "std                 0.224528               0.060280              0.085093   \n",
       "min                 0.000000               0.000000              0.000000   \n",
       "25%                 0.000000               0.000000              0.000000   \n",
       "50%                 0.000000               0.000000              0.000000   \n",
       "75%                 0.000000               0.000000              0.000000   \n",
       "max                 1.000000               1.000000              1.000000   \n",
       "\n",
       "       SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "count           1372.000000           1372.000000            1372.000000  \n",
       "mean               0.018222              0.831633               0.086006  \n",
       "std                0.133801              0.374329               0.280475  \n",
       "min                0.000000              0.000000               0.000000  \n",
       "25%                0.000000              1.000000               0.000000  \n",
       "50%                0.000000              1.000000               0.000000  \n",
       "75%                0.000000              1.000000               0.000000  \n",
       "max                1.000000              1.000000               1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your statements here\n",
    "pd.options.display.max_columns = 300\n",
    "test_data.describe(include ='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col = list(test_data.columns)\n",
    "train_col = list(train_X)\n",
    "\n",
    "miss_col = []\n",
    "for col in train_col:\n",
    "    if col not in test_col:\n",
    "        miss_col.append(col)\n",
    "        \n",
    "# add the missing columns\n",
    "for col in miss_col:\n",
    "    test_data[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.3 Standardize/Rescale the testing data using the MinMaxScaler (see Step 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "test_scaler = MinMaxScaler()\n",
    "test_scaler.fit(test_data)\n",
    "sca_test = test_scaler.transform(test_data)\n",
    "sca_test = pd.DataFrame(sca_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.4: Use the NN model or your best model to predict the results\n",
    "\n",
    "Predicting the housing price on the testing features data.\n",
    "<ol>\n",
    "    <li>Use predict function of NN to predict testData. The predictions will be in the range between 0 and 1.</li>\n",
    "    <li>If the predicted value is greater than 0.5, set it to 1, otherwise, set it to 0.\n",
    "    </li>\n",
    "    <li>Save the classification results to a CSV file: prediction-ann.csv. (for example, you may use the pandas.DataFrame.to_csv function)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your statements here\n",
    "nn_predict = model.predict(sca_test)\n",
    "pd.DataFrame(nn_predict).to_csv('prediction-ann.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Explore K-fold cross validation (15 points)\n",
    "\n",
    "K-fold cross validation is often used to handle the situation of overfitting, i.e. a model that can make good predictions on the labels of the samples that it has seen but cannot make good predictitions on unseen data.\n",
    "\n",
    "It is performed by splitting the training dataset into k subsets.\n",
    "Then, models are trained by taking turns on all subsets except one which is held out, and the model performance is evaluated on the held out validation set.\n",
    "The process is repeated until all subsets are given an opportunity to be the held out validation set. \n",
    "The performance measure is then averaged across the performance on all models.\n",
    "\n",
    "Note: Cross validation is often not used for evaluating deep learning models because of the computational expense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the reference on cross validation provided by scikit-learn:\n",
    "    <url>https://scikit-learn.org/stable/modules/cross_validation.html</url>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.1 \n",
    "Explore and implement the use of 5-fold cross validation with linear regression (Step 3).<br />\n",
    "Output the RMSE for each fold.<br/>\n",
    "Output the average RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12290787 0.14599938 0.18046102 0.1125664  0.15993343] 0.14437361904668952\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "from sklearn.model_selection import cross_val_score\n",
    "linear_rmse = cross_val_score(linear_model, train_X, train_Y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(np.sqrt(-linear_rmse), np.average(np.sqrt(-linear_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.2 \n",
    "Explore and implement the use of 5-fold cross validation with decision tree regressor (Step 4). <br />\n",
    "Output the RMSE for each fold.<br/>\n",
    "Output the average RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20451449 0.22609302 0.19139751 0.2103329  0.19745355] 0.20595829482979297\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "tree_rmse = cross_val_score(tree_model, train_X, train_Y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(np.sqrt(-tree_rmse), np.average(np.sqrt(-tree_rmse)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.3 \n",
    "Explore and implement the use of 5-fold cross validation with Neural Network (Step 6).<br />\n",
    "Output the RMSE for each fold.<br/>\n",
    "Output the average RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 1s 836us/step - loss: 50.2847 - mean_squared_error: 50.2847\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.9105 - mean_squared_error: 0.9105\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.1044 - mean_squared_error: 0.1044\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0643 - mean_squared_error: 0.0643\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0468 - mean_squared_error: 0.0468\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0200 - mean_squared_error: 0.0200\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0189 - mean_squared_error: 0.0189\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0172 - mean_squared_error: 0.0172\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 96us/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 192us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 155us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 153us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 208us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 189us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.00 - 0s 147us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 198us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 142us/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 163us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 142us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 153us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 161us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0081 - mean_squared_error: 0.00810s - loss: 0.0108 - mean_squared_error: \n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 160us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 155us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.00 - 0s 142us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 155us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 161us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 153us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0021 - mean_squared_error: 0.00210s - loss: 0.0016 - mean_squared_error: 0.\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0061 - mean_squared_error: 0.00610s - loss: 0.0062 - mean_squared_error: 0.00\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0022 - mean_squared_error: 0.00220s - loss: 0.0022 - mean_squared_error: 0.00\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.00 - 0s 101us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0016 - mean_squared_error: 0.00160s - loss: 0.0016 - mean_squared_error: 0.00\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 160us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 242us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 203us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 185us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 171us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 197us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 163us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 97us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 142us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 7.3500e-04 - mean_squared_error: 7.3500e-04\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0048 - mean_squared_error: 0.00480s - loss: 0.0031 - mean_squared_error: \n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 155us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 161us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 163us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 8.9586e-04 - mean_squared_error: 8.9586e-04\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 142us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 155us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 9.3330e-04 - mean_squared_error: 9.3330e-04\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 180us/step - loss: 6.9011e-04 - mean_squared_error: 6.9011e-04\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 97us/step - loss: 4.5707e-04 - mean_squared_error: 4.5707e-04\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 5.6134e-04 - mean_squared_error: 5.6134e-04\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 9.4630e-04 - mean_squared_error: 9.4630e-04\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 5.3050e-04 - mean_squared_error: 5.3050e-04\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 6.4967e-04 - mean_squared_error: 6.4967e-04\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 8.1262e-04 - mean_squared_error: 8.1262e-04\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 97us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 8.4295e-04 - mean_squared_error: 8.4295e-04\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 6.1433e-04 - mean_squared_error: 6.1433e-04\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 4.4986e-04 - mean_squared_error: 4.4986e-04\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 6.1927e-04 - mean_squared_error: 6.1927e-04\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 4.7132e-04 - mean_squared_error: 4.7132e-04\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 8.2145e-04 - mean_squared_error: 8.2145e-04\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 193us/step - loss: 5.6983e-04 - mean_squared_error: 5.6983e-04\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 9.1491e-04 - mean_squared_error: 9.1491e-04\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 8.5321e-04 - mean_squared_error: 8.5321e-04\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 9.5795e-04 - mean_squared_error: 9.5795e-04\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 7.0737e-04 - mean_squared_error: 7.0737e-040s - loss: 6.0759e-04 - mean_squared_error: 6.0759\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 9.0954e-04 - mean_squared_error: 9.0954e-04\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 9.0957e-04 - mean_squared_error: 9.0957e-04\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 7.1003e-04 - mean_squared_error: 7.1003e-04\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 173us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 7.1388e-04 - mean_squared_error: 7.1388e-04\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 484/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 8.5347e-04 - mean_squared_error: 8.5347e-04\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 153us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 7.1312e-04 - mean_squared_error: 7.1312e-04\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 7.6859e-04 - mean_squared_error: 7.6859e-04\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 6.0011e-04 - mean_squared_error: 6.0011e-04\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 4.8922e-04 - mean_squared_error: 4.8922e-04\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 5.9955e-04 - mean_squared_error: 5.9955e-04\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 1s 860us/step - loss: 58.3642 - mean_squared_error: 58.3642\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.9735 - mean_squared_error: 0.9735\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.1018 - mean_squared_error: 0.1018\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0605 - mean_squared_error: 0.0605\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0415 - mean_squared_error: 0.0415\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0200 - mean_squared_error: 0.0200\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 92us/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0057 - mean_squared_error: 0.00570s - loss: 0.0060 - mean_squared_error: 0.00\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 142us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 123/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0197 - mean_squared_error: 0.0197\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0025 - mean_squared_error: 0.00250s - loss: 0.0025 - mean_squared_error: 0.00\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 97us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 97us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 262/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.00 - 0s 127us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 9.7850e-04 - mean_squared_error: 9.7850e-04\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 185us/step - loss: 0.0032 - mean_squared_error: 0.00320s - loss: 0.0042 - mean_squared_error: 0.\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0010 - mean_squared_error: 0.0010  \n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 8.4955e-04 - mean_squared_error: 8.4955e-04\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 166us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 160us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0010 - mean_squared_error: 0.0010  \n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0096 - mean_squared_error: 0.00960s - loss: 0.0089 - mean_squared_error: 0.00\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 165us/step - loss: 0.0013 - mean_squared_error: 0.0013 - ETA: 0s - loss: 0.0012 - mean_squared_error: 0.00\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 179us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 7.7027e-04 - mean_squared_error: 7.7027e-04\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 218us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 7.0921e-04 - mean_squared_error: 7.0921e-04\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 4.9593e-04 - mean_squared_error: 4.9593e-04\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 5.4595e-04 - mean_squared_error: 5.4595e-04\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 167us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 153us/step - loss: 9.7417e-04 - mean_squared_error: 9.7417e-04\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 9.6303e-04 - mean_squared_error: 9.6303e-04\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 7.9179e-04 - mean_squared_error: 7.9179e-04\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0011 - mean_squared_error: 0.0011 - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0011      \n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 7.3030e-04 - mean_squared_error: 7.3030e-04\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 7.9010e-04 - mean_squared_error: 7.9010e-04\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 6.7747e-04 - mean_squared_error: 6.7747e-04\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 5.5938e-04 - mean_squared_error: 5.5938e-04\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 5.4033e-04 - mean_squared_error: 5.4033e-04\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 6.7385e-04 - mean_squared_error: 6.7385e-04\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 7.2489e-04 - mean_squared_error: 7.2489e-04\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 7.5747e-04 - mean_squared_error: 7.5747e-04\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 8.7150e-04 - mean_squared_error: 8.7150e-04\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 5.7503e-04 - mean_squared_error: 5.7503e-04\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 156us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 6.6651e-04 - mean_squared_error: 6.6651e-040s - loss: 6.5354e-04 - mean_squared_error: 6.5354e-\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 8.4444e-04 - mean_squared_error: 8.4444e-04\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 9.2795e-04 - mean_squared_error: 9.2795e-04\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0010 - mean_squared_error: 0.0010  \n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 9.5337e-04 - mean_squared_error: 9.5337e-04\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 7.3155e-04 - mean_squared_error: 7.3155e-04\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0014 - mean_squared_error: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 7.7356e-04 - mean_squared_error: 7.7356e-04\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 6.0942e-04 - mean_squared_error: 6.0942e-04\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0010 - mean_squared_error: 0.0010  \n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 7.2223e-04 - mean_squared_error: 7.2223e-04\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 9.6352e-04 - mean_squared_error: 9.6352e-04\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 7.2154e-04 - mean_squared_error: 7.2154e-04\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 6.5010e-04 - mean_squared_error: 6.5010e-04\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 8.2703e-04 - mean_squared_error: 8.2703e-04\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 1s 1ms/step - loss: 52.5573 - mean_squared_error: 52.5573\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.9027 - mean_squared_error: 0.9027\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.1043 - mean_squared_error: 0.1043\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0659 - mean_squared_error: 0.0659\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0515 - mean_squared_error: 0.0515\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0409 - mean_squared_error: 0.0409\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0217 - mean_squared_error: 0.0217\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0191 - mean_squared_error: 0.0191\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 20/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 96us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0041 - mean_squared_error: 0.00410s - loss: 0.0039 - mean_squared_error: 0.00\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0032 - mean_squared_error: 0.00320s - loss: 0.0032 - mean_squared_error: 0.00\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 185us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 207us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 183us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 175us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 196us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 186us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 196us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 161us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 186us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 194us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 212us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 194us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 214us/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 218us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 196us/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 158/500\n",
      "1167/1167 [==============================] - 0s 200us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 219us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 218us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 226us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 187us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 160us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 153us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 174us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 233us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 177us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 199us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 157us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 170us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0011 - mean_squared_error: 0.0011 - ETA: 0s - loss: 0.0010 - mean_squared_error: 0.0010      \n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 97us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 235us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 164us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 222us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 191us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 158us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 164us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 186us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 184us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 205us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 185us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 176us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 182us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 183us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 192us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.00 - 0s 115us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 146us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 0.0027 - mean_squared_error: 0.00270s - loss: 0.0027 - mean_squared_error: 0.00\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 154us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 161us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 149us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0175 - mean_squared_error: 0.01750s - loss: 0.0157 - mean_squared_error: 0.01\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 8.6127e-04 - mean_squared_error: 8.6127e-04\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 8.3103e-04 - mean_squared_error: 8.3103e-04\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 7.1170e-04 - mean_squared_error: 7.1170e-04\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 9.4156e-04 - mean_squared_error: 9.4156e-04\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 7.2282e-04 - mean_squared_error: 7.2282e-04\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0010 - mean_squared_error: 0.0010  \n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 296/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.00 - 0s 100us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.0016     - 0s 123us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 9.3878e-04 - mean_squared_error: 9.3878e-04\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 8.8559e-04 - mean_squared_error: 8.8559e-04\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0011 - mean_squared_error: 0.0011  \n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 221us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 189us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 365/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 178us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0022 - mean_squared_error: 0.00220s - loss: 0.0022 - mean_squared_error: 0.00\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0011 - mean_squared_error: 0.0011  \n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 7.3006e-04 - mean_squared_error: 7.3006e-04\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 8.3404e-04 - mean_squared_error: 8.3404e-04s: 8.9250e-04 - mean_squared_error: 8.9250\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 139us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 184us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 226us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 228us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 214us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 187us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 204us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 248us/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 212us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 247us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 191us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 162us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 9.3828e-04 - mean_squared_error: 9.3828e-04\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 6.1508e-04 - mean_squared_error: 6.1508e-04\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 148us/step - loss: 6.2832e-04 - mean_squared_error: 6.2832e-04\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 5.3391e-04 - mean_squared_error: 5.3391e-04\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 136us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 9.8312e-04 - mean_squared_error: 9.8312e-04\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 8.2087e-04 - mean_squared_error: 8.2087e-04\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 8.9425e-04 - mean_squared_error: 8.9425e-04\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 143us/step - loss: 8.1894e-04 - mean_squared_error: 8.1894e-04\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 212us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 169us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 172us/step - loss: 9.5846e-04 - mean_squared_error: 9.5846e-04\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 6.3024e-04 - mean_squared_error: 6.3024e-04\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 9.3770e-04 - mean_squared_error: 9.3770e-04\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 150us/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 7.5127e-04 - mean_squared_error: 7.5127e-04\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 5.7829e-04 - mean_squared_error: 5.7829e-04\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 99us/step - loss: 6.3499e-04 - mean_squared_error: 6.3499e-04\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 5.9245e-04 - mean_squared_error: 5.9245e-04\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 6.4014e-04 - mean_squared_error: 6.4014e-04\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 9.3924e-04 - mean_squared_error: 9.3924e-04\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 1/500\n",
      "1167/1167 [==============================] - 1s 918us/step - loss: 54.7211 - mean_squared_error: 54.7211\n",
      "Epoch 2/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.9330 - mean_squared_error: 0.9330\n",
      "Epoch 3/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0960 - mean_squared_error: 0.0960\n",
      "Epoch 4/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0584 - mean_squared_error: 0.0584\n",
      "Epoch 5/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0456 - mean_squared_error: 0.0456\n",
      "Epoch 6/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
      "Epoch 7/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Epoch 8/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
      "Epoch 9/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 10/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 11/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0217 - mean_squared_error: 0.0217\n",
      "Epoch 12/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0202 - mean_squared_error: 0.0202\n",
      "Epoch 13/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0185 - mean_squared_error: 0.0185\n",
      "Epoch 14/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 15/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
      "Epoch 16/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
      "Epoch 17/500\n",
      "1167/1167 [==============================] - 0s 144us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 18/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 19/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 21/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 22/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 23/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 24/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 25/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 26/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 27/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 28/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 29/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 30/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 31/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 32/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 33/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 34/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 35/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 36/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 37/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 38/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 39/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 40/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 41/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 42/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 43/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 44/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 45/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 46/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0049 - mean_squared_error: 0.00490s - loss: 0.0049 - mean_squared_error: 0.00\n",
      "Epoch 47/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 48/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 49/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 50/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 51/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 52/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 53/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 54/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 55/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 56/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 57/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 58/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 59/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 60/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 61/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 62/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 63/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 64/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 65/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 66/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 67/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 68/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 69/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 70/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 71/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 72/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 73/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 74/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 75/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 76/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 77/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 78/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 79/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 80/500\n",
      "1167/1167 [==============================] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.00 - 0s 96us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 81/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 82/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 83/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 84/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 85/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 86/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 87/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 88/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 89/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0038 - mean_squared_error: 0.00380s - loss: 0.0039 - mean_squared_error: 0.00\n",
      "Epoch 90/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 91/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 92/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 93/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 94/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 95/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 96/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 97/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 98/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 99/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 100/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 101/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 102/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 103/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 104/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 105/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 106/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 107/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 108/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 109/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 110/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 111/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 112/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 113/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 114/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 115/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 116/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 117/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 118/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 119/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 120/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 121/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 122/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 123/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 124/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 125/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 126/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 127/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 128/500\n",
      "1167/1167 [==============================] - 0s 168us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 129/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 130/500\n",
      "1167/1167 [==============================] - 0s 132us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 131/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 132/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 133/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 134/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 135/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 136/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 137/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 138/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 139/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 140/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 141/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 142/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 143/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 144/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 145/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 146/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 147/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 148/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 149/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 150/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 151/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 152/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0031 - mean_squared_error: 0.00310s - loss: 0.0032 - mean_squared_error: 0.00\n",
      "Epoch 153/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 154/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 155/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 156/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 157/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 159/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 160/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 161/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 162/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 163/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 164/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 165/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 166/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 167/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 168/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 169/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0095 - mean_squared_error: 0.00950s - loss: 0.0102 - mean_squared_error: 0.01\n",
      "Epoch 170/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 171/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 172/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 173/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 174/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 175/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 176/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 177/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 178/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 179/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 180/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 181/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 182/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 183/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 184/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 185/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 186/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 187/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 188/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 189/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 190/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 191/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 192/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 193/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 194/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 195/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 196/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 197/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 198/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 199/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 200/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 201/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 202/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 203/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 204/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 205/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 206/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 207/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 208/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 209/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 210/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0040 - mean_squared_error: 0.00400s - loss: 0.0042 - mean_squared_error: 0.00\n",
      "Epoch 211/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 212/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 213/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 214/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 215/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 216/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 217/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 218/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
      "Epoch 219/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 220/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 221/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 222/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 223/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 224/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 225/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 226/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 227/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 228/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 229/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 230/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 231/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 232/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 233/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 234/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 235/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 236/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 237/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 238/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 239/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 240/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 241/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 242/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 243/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 244/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 245/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 246/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 247/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 248/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 249/500\n",
      "1167/1167 [==============================] - 0s 151us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 250/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 251/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 252/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 253/500\n",
      "1167/1167 [==============================] - 0s 138us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 254/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 255/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 256/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 257/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0017 - mean_squared_error: 0.00170s - loss: 0.0017 - mean_squared_error: 0.\n",
      "Epoch 258/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 259/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 260/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 261/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 262/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 263/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 264/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 265/500\n",
      "1167/1167 [==============================] - 0s 98us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 266/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 267/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 268/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 269/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 270/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 271/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 272/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 273/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 274/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 275/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 276/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 277/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 278/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 279/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 280/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 281/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 282/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 283/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 284/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 285/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 286/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 287/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 288/500\n",
      "1167/1167 [==============================] - 0s 131us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 289/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 290/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 291/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 292/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 293/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 294/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 295/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 297/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 298/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 299/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 300/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 301/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 302/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 303/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 304/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 305/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 306/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 307/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 308/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 309/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 9.4459e-04 - mean_squared_error: 9.4459e-04\n",
      "Epoch 310/500\n",
      "1167/1167 [==============================] - 0s 101us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 311/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 9.5858e-04 - mean_squared_error: 9.5858e-04\n",
      "Epoch 312/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 313/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 314/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 9.2425e-04 - mean_squared_error: 9.2425e-04\n",
      "Epoch 315/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 316/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 317/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 318/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 319/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 320/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 321/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 322/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 323/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 324/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 325/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 326/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 327/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 328/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 329/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 330/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 331/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 332/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0022 - mean_squared_error: 0.00220s - loss: 0.0021 - mean_squared_error: 0.00\n",
      "Epoch 333/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 334/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 335/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 336/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 337/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 338/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 339/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 340/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 341/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 342/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 8.0228e-04 - mean_squared_error: 8.0228e-04\n",
      "Epoch 343/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 344/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 345/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 346/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 347/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 348/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 349/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0028 - mean_squared_error: 0.00280s - loss: 0.0030 - mean_squared_error: 0.00\n",
      "Epoch 350/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 351/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 352/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 353/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 354/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 355/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 356/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 357/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 358/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 8.1521e-04 - mean_squared_error: 8.1521e-04\n",
      "Epoch 359/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0011 - mean_squared_error: 0.0011  \n",
      "Epoch 360/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 361/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 362/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 363/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 364/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 366/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 367/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 368/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 369/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 370/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 371/500\n",
      "1167/1167 [==============================] - 0s 152us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 372/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 373/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 374/500\n",
      "1167/1167 [==============================] - 0s 135us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 375/500\n",
      "1167/1167 [==============================] - 0s 133us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 376/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 377/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 378/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 379/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 380/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 381/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 382/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 383/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 9.2468e-04 - mean_squared_error: 9.2468e-04\n",
      "Epoch 384/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 385/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 386/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 387/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 388/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 389/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 390/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 391/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 392/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 393/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 394/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 395/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 396/500\n",
      "1167/1167 [==============================] - 0s 134us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 397/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 398/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 399/500\n",
      "1167/1167 [==============================] - 0s 128us/step - loss: 9.6140e-04 - mean_squared_error: 9.6140e-04\n",
      "Epoch 400/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 7.9010e-04 - mean_squared_error: 7.9010e-04\n",
      "Epoch 401/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 402/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 403/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 404/500\n",
      "1167/1167 [==============================] - 0s 118us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 405/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 406/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 407/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 408/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0216 - mean_squared_error: 0.0216\n",
      "Epoch 409/500\n",
      "1167/1167 [==============================] - 0s 103us/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 410/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 411/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 412/500\n",
      "1167/1167 [==============================] - 0s 93us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 413/500\n",
      "1167/1167 [==============================] - 0s 145us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 414/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 415/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 416/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 9.7549e-04 - mean_squared_error: 9.7549e-04\n",
      "Epoch 417/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 8.7960e-04 - mean_squared_error: 8.7960e-04\n",
      "Epoch 418/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 6.2755e-04 - mean_squared_error: 6.2755e-04\n",
      "Epoch 419/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 420/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 9.6010e-04 - mean_squared_error: 9.6010e-04\n",
      "Epoch 421/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 6.1413e-04 - mean_squared_error: 6.1413e-04\n",
      "Epoch 422/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 6.2372e-04 - mean_squared_error: 6.2372e-04\n",
      "Epoch 423/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 7.7073e-04 - mean_squared_error: 7.7073e-04\n",
      "Epoch 424/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 8.0301e-04 - mean_squared_error: 8.0301e-04\n",
      "Epoch 425/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 7.1686e-04 - mean_squared_error: 7.1686e-04\n",
      "Epoch 426/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 9.5080e-04 - mean_squared_error: 9.5080e-04\n",
      "Epoch 427/500\n",
      "1167/1167 [==============================] - 0s 122us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 428/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 429/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 430/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 431/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 6.9741e-04 - mean_squared_error: 6.9741e-04\n",
      "Epoch 432/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 433/500\n",
      "1167/1167 [==============================] - 0s 127us/step - loss: 9.2000e-04 - mean_squared_error: 9.2000e-04\n",
      "Epoch 434/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 435/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 436/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 437/500\n",
      "1167/1167 [==============================] - 0s 102us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 438/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 439/500\n",
      "1167/1167 [==============================] - 0s 121us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 440/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 441/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 442/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 443/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 444/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 8.9462e-04 - mean_squared_error: 8.9462e-04\n",
      "Epoch 445/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 446/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 447/500\n",
      "1167/1167 [==============================] - 0s 137us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 448/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 449/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 9.7708e-04 - mean_squared_error: 9.7708e-04\n",
      "Epoch 450/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 451/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 452/500\n",
      "1167/1167 [==============================] - 0s 111us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 453/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 454/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 455/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 456/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 457/500\n",
      "1167/1167 [==============================] - 0s 106us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 458/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0010 - mean_squared_error: 0.0010  \n",
      "Epoch 459/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 460/500\n",
      "1167/1167 [==============================] - 0s 96us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 461/500\n",
      "1167/1167 [==============================] - 0s 105us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 462/500\n",
      "1167/1167 [==============================] - 0s 116us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 463/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 464/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 465/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 466/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 467/500\n",
      "1167/1167 [==============================] - 0s 113us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 468/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 469/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 470/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0020 - mean_squared_error: 0.00200s - loss: 0.0021 - mean_squared_error: 0.00\n",
      "Epoch 471/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 472/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 473/500\n",
      "1167/1167 [==============================] - 0s 100us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 474/500\n",
      "1167/1167 [==============================] - 0s 107us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 475/500\n",
      "1167/1167 [==============================] - 0s 110us/step - loss: 8.3805e-04 - mean_squared_error: 8.3805e-04\n",
      "Epoch 476/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 477/500\n",
      "1167/1167 [==============================] - 0s 109us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 478/500\n",
      "1167/1167 [==============================] - 0s 108us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 479/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 480/500\n",
      "1167/1167 [==============================] - 0s 104us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 481/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 482/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 483/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 484/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 485/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 486/500\n",
      "1167/1167 [==============================] - 0s 141us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 487/500\n",
      "1167/1167 [==============================] - 0s 125us/step - loss: 6.1813e-04 - mean_squared_error: 6.1813e-04\n",
      "Epoch 488/500\n",
      "1167/1167 [==============================] - 0s 124us/step - loss: 6.7701e-04 - mean_squared_error: 6.7701e-04\n",
      "Epoch 489/500\n",
      "1167/1167 [==============================] - 0s 140us/step - loss: 6.0228e-04 - mean_squared_error: 6.0228e-04\n",
      "Epoch 490/500\n",
      "1167/1167 [==============================] - 0s 126us/step - loss: 7.8766e-04 - mean_squared_error: 7.8766e-04\n",
      "Epoch 491/500\n",
      "1167/1167 [==============================] - 0s 120us/step - loss: 8.4236e-04 - mean_squared_error: 8.4236e-04\n",
      "Epoch 492/500\n",
      "1167/1167 [==============================] - 0s 130us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 493/500\n",
      "1167/1167 [==============================] - 0s 114us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 494/500\n",
      "1167/1167 [==============================] - 0s 123us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 495/500\n",
      "1167/1167 [==============================] - 0s 119us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 496/500\n",
      "1167/1167 [==============================] - 0s 129us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 497/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 498/500\n",
      "1167/1167 [==============================] - 0s 112us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 499/500\n",
      "1167/1167 [==============================] - 0s 115us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 500/500\n",
      "1167/1167 [==============================] - 0s 117us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 1/500\n",
      "1168/1168 [==============================] - 1s 972us/step - loss: 55.7060 - mean_squared_error: 55.7060\n",
      "Epoch 2/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.8831 - mean_squared_error: 0.8831\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0887 - mean_squared_error: 0.0887\n",
      "Epoch 4/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0554 - mean_squared_error: 0.0554\n",
      "Epoch 5/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Epoch 6/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
      "Epoch 7/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Epoch 8/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 9/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
      "Epoch 10/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0186 - mean_squared_error: 0.0186\n",
      "Epoch 11/500\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 0.0168 - mean_squared_error: 0.0168\n",
      "Epoch 12/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
      "Epoch 13/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 14/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 15/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 16/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 17/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 18/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 19/500\n",
      "1168/1168 [==============================] - 0s 100us/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 20/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 21/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 22/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 23/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 24/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 25/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 26/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 27/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 28/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 29/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 30/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 31/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 32/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 33/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 34/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 35/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 36/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 37/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 38/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 39/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 40/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 41/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 42/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 43/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 44/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 45/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 46/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 47/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 48/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 49/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 50/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 51/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 52/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 53/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 54/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 55/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 56/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 57/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 58/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 59/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 60/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 61/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 62/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 63/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 64/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 65/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 66/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 67/500\n",
      "1168/1168 [==============================] - 0s 129us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 68/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 69/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 70/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 71/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 72/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 73/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 74/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 75/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 76/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 77/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 78/500\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 79/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 80/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 81/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 82/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 83/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 84/500\n",
      "1168/1168 [==============================] - 0s 131us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 85/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 86/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 87/500\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 88/500\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 89/500\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 90/500\n",
      "1168/1168 [==============================] - 0s 129us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 91/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 92/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 93/500\n",
      "1168/1168 [==============================] - 0s 147us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 94/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 95/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 96/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 97/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 98/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 99/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 100/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 101/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 102/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 103/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 104/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 105/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 106/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 107/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 108/500\n",
      "1168/1168 [==============================] - 0s 99us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 109/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 110/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 111/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 112/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 113/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 114/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 115/500\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 116/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 117/500\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 118/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 119/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 120/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 121/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 122/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 123/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 124/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 125/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 126/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 127/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 128/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 129/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 130/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 131/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 132/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 133/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0051 - mean_squared_error: 0.00510s - loss: 0.0049 - mean_squared_error: 0.00\n",
      "Epoch 134/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 135/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 136/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 137/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 138/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 139/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 140/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 141/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 142/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0091 - mean_squared_error: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 144/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 145/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 146/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 147/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 148/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 149/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 150/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 151/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 152/500\n",
      "1168/1168 [==============================] - 0s 96us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 153/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 154/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 155/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 156/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 0.0040 - mean_squared_error: 0.00400s - loss: 0.0034 - mean_squared_error: 0.\n",
      "Epoch 157/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 158/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 159/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 160/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 161/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 162/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 163/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 164/500\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 0.0171 - mean_squared_error: 0.0171\n",
      "Epoch 165/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 166/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 167/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 168/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 169/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 170/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 171/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 172/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 173/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 174/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 175/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 176/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 177/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 178/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 179/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 180/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 181/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 182/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 183/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 184/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 185/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 186/500\n",
      "1168/1168 [==============================] - 0s 101us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 187/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 188/500\n",
      "1168/1168 [==============================] - 0s 159us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 189/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 190/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 191/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 192/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 193/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 194/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 195/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 196/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 197/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 198/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 199/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 200/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 201/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 202/500\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 203/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 204/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 205/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 206/500\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 207/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 208/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 209/500\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 210/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 211/500\n",
      "1168/1168 [==============================] - 0s 131us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 212/500\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 213/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 214/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 215/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 216/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 217/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 218/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 219/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 220/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 221/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 222/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 223/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 224/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 225/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 226/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 227/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 228/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 229/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 230/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 231/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 232/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 233/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 234/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 235/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 236/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 237/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 238/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 239/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 240/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0017 - mean_squared_error: 0.00170s - loss: 0.0019 - mean_squared_error: 0.00\n",
      "Epoch 241/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 242/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0025 - mean_squared_error: 0.0025 - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.00\n",
      "Epoch 243/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 244/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 245/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 246/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 247/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 248/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 249/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 250/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 251/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 252/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 253/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 254/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 255/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 256/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 257/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 258/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 259/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 260/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 261/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 262/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 263/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 264/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 265/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 266/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 8.9546e-04 - mean_squared_error: 8.9546e-04\n",
      "Epoch 267/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 268/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 269/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 270/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 8.9007e-04 - mean_squared_error: 8.9007e-04\n",
      "Epoch 271/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 272/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 273/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 9.1989e-04 - mean_squared_error: 9.1989e-04\n",
      "Epoch 274/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 275/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 276/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 277/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 278/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 279/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 280/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 282/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 283/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 284/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 285/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 286/500\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
      "Epoch 287/500\n",
      "1168/1168 [==============================] - 0s 158us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 288/500\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 289/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 290/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 291/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 292/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 293/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 294/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 295/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 296/500\n",
      "1168/1168 [==============================] - 0s 103us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 297/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 298/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 299/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 300/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 7.5972e-04 - mean_squared_error: 7.5972e-04\n",
      "Epoch 301/500\n",
      "1168/1168 [==============================] - 0s 102us/step - loss: 7.0280e-04 - mean_squared_error: 7.0280e-04\n",
      "Epoch 302/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 6.8460e-04 - mean_squared_error: 6.8460e-04\n",
      "Epoch 303/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 4.7528e-04 - mean_squared_error: 4.7528e-04\n",
      "Epoch 304/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 9.4988e-04 - mean_squared_error: 9.4988e-04\n",
      "Epoch 305/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0011 - mean_squared_error: 0.0011  \n",
      "Epoch 306/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 307/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 308/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 309/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 310/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 8.3994e-04 - mean_squared_error: 8.3994e-04\n",
      "Epoch 311/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 312/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 313/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 314/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 315/500\n",
      "1168/1168 [==============================] - 0s 106us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 316/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 317/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 318/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 319/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 320/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 9.8698e-04 - mean_squared_error: 9.8698e-04\n",
      "Epoch 321/500\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 322/500\n",
      "1168/1168 [==============================] - 0s 166us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 323/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 324/500\n",
      "1168/1168 [==============================] - 0s 130us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 325/500\n",
      "1168/1168 [==============================] - 0s 130us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 326/500\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 327/500\n",
      "1168/1168 [==============================] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.00 - 0s 126us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 328/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 329/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 330/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 331/500\n",
      "1168/1168 [==============================] - 0s 107us/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 332/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 333/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 334/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 335/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 336/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 337/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 338/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 339/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 340/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 341/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 342/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 343/500\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 344/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 345/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 346/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0022 - mean_squared_error: 0.00220s - loss: 0.0026 - mean_squared_error: 0.\n",
      "Epoch 347/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 348/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 349/500\n",
      "1168/1168 [==============================] - 0s 131us/step - loss: 7.6623e-04 - mean_squared_error: 7.6623e-04\n",
      "Epoch 350/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 7.1716e-04 - mean_squared_error: 7.1716e-04\n",
      "Epoch 351/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 7.1495e-04 - mean_squared_error: 7.1495e-040s - loss: 7.2515e-04 - mean_squared_error: 7.2515e-\n",
      "Epoch 352/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 353/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 354/500\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 355/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 356/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 357/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 0.0011 - mean_squared_error: 0.0011  \n",
      "Epoch 358/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 359/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 360/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 361/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 362/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 363/500\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 364/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 365/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 366/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 367/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 8.9996e-04 - mean_squared_error: 8.9996e-04\n",
      "Epoch 368/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 369/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 370/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 371/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 372/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 373/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 374/500\n",
      "1168/1168 [==============================] - 0s 129us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 375/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 376/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 377/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 8.5418e-04 - mean_squared_error: 8.5418e-04\n",
      "Epoch 378/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 379/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 380/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 381/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 382/500\n",
      "1168/1168 [==============================] - 0s 158us/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 383/500\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 384/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 385/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 386/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 387/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 388/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 389/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 390/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 391/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 392/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 393/500\n",
      "1168/1168 [==============================] - 0s 149us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 394/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 395/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 9.9169e-04 - mean_squared_error: 9.9169e-04\n",
      "Epoch 396/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 397/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 398/500\n",
      "1168/1168 [==============================] - 0s 116us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 399/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 8.9660e-04 - mean_squared_error: 8.9660e-04\n",
      "Epoch 400/500\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 401/500\n",
      "1168/1168 [==============================] - 0s 147us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 402/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 403/500\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 404/500\n",
      "1168/1168 [==============================] - 0s 163us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 405/500\n",
      "1168/1168 [==============================] - 0s 122us/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 406/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 407/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0163 - mean_squared_error: 0.0163\n",
      "Epoch 408/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 409/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 410/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 411/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 412/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 6.9597e-04 - mean_squared_error: 6.9597e-04\n",
      "Epoch 413/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 5.1715e-04 - mean_squared_error: 5.1715e-04\n",
      "Epoch 414/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 5.9586e-04 - mean_squared_error: 5.9586e-04\n",
      "Epoch 415/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 5.3837e-04 - mean_squared_error: 5.3837e-04\n",
      "Epoch 416/500\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 3.5368e-04 - mean_squared_error: 3.5368e-04\n",
      "Epoch 417/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 124us/step - loss: 5.7598e-04 - mean_squared_error: 5.7598e-04\n",
      "Epoch 418/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 3.9693e-04 - mean_squared_error: 3.9693e-04\n",
      "Epoch 419/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 3.0361e-04 - mean_squared_error: 3.0361e-04\n",
      "Epoch 420/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 2.4083e-04 - mean_squared_error: 2.4083e-04\n",
      "Epoch 421/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 4.9086e-04 - mean_squared_error: 4.9086e-04\n",
      "Epoch 422/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 8.5566e-04 - mean_squared_error: 8.5566e-04\n",
      "Epoch 423/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 424/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 8.4537e-04 - mean_squared_error: 8.4537e-04\n",
      "Epoch 425/500\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 8.2422e-04 - mean_squared_error: 8.2422e-04\n",
      "Epoch 426/500\n",
      "1168/1168 [==============================] - 0s 167us/step - loss: 5.3436e-04 - mean_squared_error: 5.3436e-04\n",
      "Epoch 427/500\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 9.1133e-04 - mean_squared_error: 9.1133e-04\n",
      "Epoch 428/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 8.8560e-04 - mean_squared_error: 8.8560e-04\n",
      "Epoch 429/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 430/500\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 431/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 432/500\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 433/500\n",
      "1168/1168 [==============================] - 0s 164us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 434/500\n",
      "1168/1168 [==============================] - 0s 170us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 435/500\n",
      "1168/1168 [==============================] - 0s 126us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 436/500\n",
      "1168/1168 [==============================] - 0s 120us/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 437/500\n",
      "1168/1168 [==============================] - 0s 153us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 438/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 439/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 440/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 441/500\n",
      "1168/1168 [==============================] - 0s 146us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 442/500\n",
      "1168/1168 [==============================] - 0s 110us/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 443/500\n",
      "1168/1168 [==============================] - 0s 145us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 444/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 445/500\n",
      "1168/1168 [==============================] - 0s 105us/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 446/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 447/500\n",
      "1168/1168 [==============================] - 0s 130us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 448/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 449/500\n",
      "1168/1168 [==============================] - 0s 119us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 450/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 451/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 452/500\n",
      "1168/1168 [==============================] - 0s 112us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 453/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 454/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 455/500\n",
      "1168/1168 [==============================] - 0s 124us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 456/500\n",
      "1168/1168 [==============================] - 0s 184us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 457/500\n",
      "1168/1168 [==============================] - 0s 174us/step - loss: 9.5160e-04 - mean_squared_error: 9.5160e-04\n",
      "Epoch 458/500\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 7.1625e-04 - mean_squared_error: 7.1625e-04\n",
      "Epoch 459/500\n",
      "1168/1168 [==============================] - 0s 153us/step - loss: 6.7837e-04 - mean_squared_error: 6.7837e-04\n",
      "Epoch 460/500\n",
      "1168/1168 [==============================] - 0s 104us/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 461/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 462/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 8.2098e-04 - mean_squared_error: 8.2098e-04\n",
      "Epoch 463/500\n",
      "1168/1168 [==============================] - 0s 109us/step - loss: 5.5370e-04 - mean_squared_error: 5.5370e-04\n",
      "Epoch 464/500\n",
      "1168/1168 [==============================] - 0s 113us/step - loss: 4.4904e-04 - mean_squared_error: 4.4904e-04\n",
      "Epoch 465/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 3.5426e-04 - mean_squared_error: 3.5426e-04\n",
      "Epoch 466/500\n",
      "1168/1168 [==============================] - 0s 125us/step - loss: 6.4625e-04 - mean_squared_error: 6.4625e-04\n",
      "Epoch 467/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 4.7734e-04 - mean_squared_error: 4.7734e-04\n",
      "Epoch 468/500\n",
      "1168/1168 [==============================] - 0s 108us/step - loss: 3.7416e-04 - mean_squared_error: 3.7416e-04\n",
      "Epoch 469/500\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 6.6676e-04 - mean_squared_error: 6.6676e-04\n",
      "Epoch 470/500\n",
      "1168/1168 [==============================] - 0s 131us/step - loss: 4.3581e-04 - mean_squared_error: 4.3581e-04\n",
      "Epoch 471/500\n",
      "1168/1168 [==============================] - 0s 115us/step - loss: 3.3078e-04 - mean_squared_error: 3.3078e-04\n",
      "Epoch 472/500\n",
      "1168/1168 [==============================] - 0s 169us/step - loss: 3.6204e-04 - mean_squared_error: 3.6204e-04\n",
      "Epoch 473/500\n",
      "1168/1168 [==============================] - 0s 117us/step - loss: 4.6883e-04 - mean_squared_error: 4.6883e-04\n",
      "Epoch 474/500\n",
      "1168/1168 [==============================] - 0s 148us/step - loss: 3.5302e-04 - mean_squared_error: 3.5302e-04\n",
      "Epoch 475/500\n",
      "1168/1168 [==============================] - 0s 192us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 476/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 477/500\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 478/500\n",
      "1168/1168 [==============================] - 0s 153us/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 479/500\n",
      "1168/1168 [==============================] - 0s 172us/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 480/500\n",
      "1168/1168 [==============================] - 0s 160us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 481/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 482/500\n",
      "1168/1168 [==============================] - 0s 118us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 483/500\n",
      "1168/1168 [==============================] - 0s 121us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 484/500\n",
      "1168/1168 [==============================] - 0s 111us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 485/500\n",
      "1168/1168 [==============================] - 0s 114us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 486/500\n",
      "1168/1168 [==============================] - 0s 123us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 487/500\n",
      "1168/1168 [==============================] - 0s 161us/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 488/500\n",
      "1168/1168 [==============================] - 0s 127us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 489/500\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 490/500\n",
      "1168/1168 [==============================] - 0s 172us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 491/500\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 7.8924e-04 - mean_squared_error: 7.8924e-04\n",
      "Epoch 492/500\n",
      "1168/1168 [==============================] - 0s 163us/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 493/500\n",
      "1168/1168 [==============================] - 0s 158us/step - loss: 7.4119e-04 - mean_squared_error: 7.4119e-04\n",
      "Epoch 494/500\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 5.3408e-04 - mean_squared_error: 5.3408e-04\n",
      "Epoch 495/500\n",
      "1168/1168 [==============================] - 0s 164us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 496/500\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 6.8341e-04 - mean_squared_error: 6.8341e-04\n",
      "Epoch 497/500\n",
      "1168/1168 [==============================] - 0s 185us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 498/500\n",
      "1168/1168 [==============================] - 0s 164us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 499/500\n",
      "1168/1168 [==============================] - 0s 128us/step - loss: 8.6872e-04 - mean_squared_error: 8.6872e-04\n",
      "Epoch 500/500\n",
      "1168/1168 [==============================] - 0s 163us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "[0.14144958 0.18618574 0.2018516  0.15575827 0.16409849] 0.16986873570664132\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(150, kernel_initializer='normal', activation='relu', input_dim=300))\n",
    "    model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu')) \n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=nn_model, batch_size=32, epochs=500)\n",
    "nn_rmse = cross_val_score(estimator, sca_all_feature, train_Y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(np.sqrt(-nn_rmse), np.average(np.sqrt(-nn_rmse)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 Build another model which out performs the above models (10 points)\n",
    "<ol>Notes:\n",
    "<li>The model should not be one of the 3 models implemented above.</li>\n",
    "<li>The model has to be evaluated using RMSE with 5-fold cross validation.</li>\n",
    "<li>The points you get in the step depends on your model's performance. It will be calculated by the following formula: <br/>\n",
    "<ul>\n",
    "<li>max{ 0, (Max_points_for_step_8) * (0.2 - Your_RMSE) / (0.2 - 0.02) }</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11959819 0.13981851 0.13371459 0.11631434 0.12803799] 0.12749672596302425\n"
     ]
    }
   ],
   "source": [
    "# Put your statements here\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)#disable future warnings\n",
    "import xgboost as xgb\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=180, \n",
    "    min_child_weight=7,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "rmse = cross_val_score(model_xgb, train_X, train_Y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(np.sqrt(-rmse), np.average(np.sqrt(-rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 Submission\n",
    "Submit your jupyter notebook (.ipynb) and the classification results (nn_predictions.csv) to Canvas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
